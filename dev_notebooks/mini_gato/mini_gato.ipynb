{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4cd771e9-8a0c-4b7a-90ee-752b56e0ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(8).reshape(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f10af94c-6080-4d3c-98f0-fa965914970f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "23f7ad70-1d6e-4a92-a0d5-962e51d099c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2, 2, 2).is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a6e6854-9a4a-4954-a98a-b0b335f2489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(4, 2)\n",
    "x.view(2, 2, 2).is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4724d446-907b-44a8-9a5c-c6936f5cb386",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "x.t().view(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82454cc4-eb64-44b7-abb7-6cf0dcf134cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f6b528-38d4-42f7-9dbb-48d7e9d27f56",
   "metadata": {},
   "source": [
    "# MiniGato\n",
    "\n",
    "From the paper [A Generalist Agent](https://arxiv.org/abs/2205.06175).\n",
    "\n",
    "The paper doesn't introduce a new architecture. Instead, the paper is all about tokenizing, embedding, and sequencing data from multiple modalities (text, image, proprioception) in such a way that it can be learned by a transformer.\n",
    "\n",
    "Reproducing the paper is more of a software design exercise than an ML research exercise. How would you structure the data manipulation code – the tokenization, embedding, and sequencing of different modalities – in a way that's correct, easy to understand and extend, and performant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf53c804-965d-4fb2-bf74-b438c00169d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mini_gato.util' from '/home/eihli/src/mini_gato/mini_gato/util.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mini_gato\n",
    "import mini_gato.util\n",
    "import importlib\n",
    "importlib.reload(mini_gato.util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ef7230-f75d-4c5a-9efb-919b14d0ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import cycle\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pdb\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "from typing import List, Protocol\n",
    "from dataclasses import dataclass, fields\n",
    "import datasets\n",
    "from einops import rearrange\n",
    "from functools import partial\n",
    "from mini_gato.nano_gpt import GPT, GPTConfig\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import minari\n",
    "from mini_gato.util import (\n",
    "    tensor_as_gif, TransformDataset,\n",
    "    images_to_patches, patches_to_images, normalize_to_between_minus_one_plus_one,\n",
    "    apply_along_dimension, discretize, undiscretize,\n",
    "    interleave, deinterleave,\n",
    ")\n",
    "import minigrid.core\n",
    "import requests\n",
    "from timm.models.resnetv2 import ResNetV2\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61391e79-d4e3-40c7-b16c-f9c229a99f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = tiktoken.get_encoding(\"r50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4288e6c6-a5ee-4196-af33-633a971d68e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6513, 30973]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.encode(\"foobar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd5a813a-f41b-435b-b76f-4c143ebd3b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.eot_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e1dec-bed5-4709-bc8f-4a70e1e02667",
   "metadata": {},
   "source": [
    "## Tokenization [§ 2.1](https://arxiv.org/pdf/2205.06175)\n",
    "\n",
    "> There are infinite possible ways to transform data into tokens, including directly using the raw underlying byte stream.\n",
    "\n",
    "We're going to start off with a certain set of tokenization strategies for a certain set of modalities. We might want to expand that in the future. When that happens, I don't want to have to edit code in the PyTorch Module that implements our model code. I'd rather be able to add a new class of modality that implements a \"tokenization\" signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed204ac-cb60-4ff0-b4e9-5e11694307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTokenizer(Protocol):\n",
    "    n_vocab: int\n",
    "    eot_token: int\n",
    "    def encode(self, text: str) -> List[int]:\n",
    "        ...\n",
    "    def decode(self, tokens: List[int]) -> str:\n",
    "        ...\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, text_tokenizer: TextTokenizer):\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.eot_token = text_tokenizer.eot_token\n",
    "        self.n_text = text_tokenizer.n_vocab\n",
    "        self.n_discrete = 1024\n",
    "        self.n_modalities = 1024\n",
    "        self.boa_token = 1023  # Separator between observation and action.\n",
    "\n",
    "    # It's useful to know if tokens are of a particular modality – text, image, discrete, etc...\n",
    "    #\n",
    "    # Why?\n",
    "    #\n",
    "    # Embedding, for example. Images get embedded with a ResNetV2 block. Text and\n",
    "    # discrete get embedded with an nn.Embedding lookup table.\n",
    "    #\n",
    "    # We can tell what modality something is by simply checking the range of its tokens.\n",
    "    # Text is in the range [0, 50256) for the tiktoken tokenizer.\n",
    "    # Discrete and continuous are in the range [50257, 51281) – the 1024 tokens after vocab.\n",
    "    # Images are floats and have a different shape because they get patched.\n",
    "    def is_text(self, tokens: torch.Tensor) -> bool:\n",
    "        return 0 <= tokens[0, 0, 0] < self.n_text\n",
    "\n",
    "    def is_discrete(self, tokens: torch.Tensor) -> bool:\n",
    "        return self.n_text <= tokens[0, 0, 0] < self.n_text + self.n_discrete\n",
    "\n",
    "    def is_image(self, tokens: torch.Tensor) -> bool:\n",
    "        return tokens.size(-1) > 1  # Images are the only modality that have a channel dim > 1.\n",
    "\n",
    "    def encode_text(self, text: str) -> torch.Tensor:\n",
    "        return torch.tensor([self.eot_token, *self.text_tokenizer.encode(text), self.eot_token]).reshape(1, -1, 1)\n",
    "\n",
    "    def decode_text(self, tokens: torch.Tensor) -> str:\n",
    "        return self.text_tokenizer.decode(tokens.squeeze()[1:-1].tolist())\n",
    "        \n",
    "    def encode_discrete(self, tokens: List[int], is_action=False) -> torch.Tensor:\n",
    "        if is_action:\n",
    "            return (torch.tensor([self.boa_token] + tokens) + self.n_text).reshape(1, -1, 1)\n",
    "        else:\n",
    "            return (torch.tensor(tokens) + self.n_text).reshape(1, -1, 1)\n",
    "        \n",
    "    def decode_discrete(self, tokens: torch.Tensor) -> List[int]:\n",
    "        return (tokens - self.n_text).squeeze().tolist()\n",
    "\n",
    "    # TODO:\n",
    "    # The paper says to mu-law encode continuous values.\n",
    "    # We're not doing that yet.\n",
    "    def encode_continuous(self, tokens: List[float], is_action=False) -> torch.Tensor:\n",
    "        if is_action:\n",
    "            return (discretize(torch.tensor([self.boa_token] + tokens)) + self.n_text).reshape(1, -1, 1)\n",
    "        else:\n",
    "            return (discretize(torch.tensor(tokens)) + self.n_text).reshape(1, -1, 1)\n",
    "\n",
    "    # This is going to be a lossy decode. The paper says to clip companded values so that\n",
    "    # they fall within the range [-1, 1]. The paper says actions are only defined in the range [-1, 1]\n",
    "    # for all of their environments, so it doesn't hurt in practice. But if you expect to be able\n",
    "    # to compand/uncompand, you'll be disappointed.\n",
    "    def decode_continuous(self, tokens: torch.Tensor) -> List[float]:\n",
    "        return undiscretize(self, tokens).tolist()\n",
    "\n",
    "    def encode_image(self, image, patch_size=16):\n",
    "        patches = images_to_patches(image, patch_size=patch_size)\n",
    "        xs = (\n",
    "            apply_along_dimension(\n",
    "                normalize_to_between_minus_one_plus_one, 1, patches\n",
    "            )\n",
    "            / math.sqrt(patch_size)\n",
    "        )        \n",
    "        return xs.unsqueeze(0)\n",
    "    \n",
    "    def decode_image(self, tokens, image_shape=(3, 192, 192), patch_size=16):\n",
    "        # Lossy because I'm not saving the values used for scaling from encoding.\n",
    "        patches = (tokens * math.sqrt(patch_size) + 1) / 2\n",
    "        images = patches_to_images(patches, image_shape, patch_size=patch_size)\n",
    "        return images        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e86485-176f-4e47-b32b-ff94f8f4a663",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0059cf4a-6e8f-4174-91e9-baff3e2ed856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.0000, -1.5000,  0.0000,  1.5000,  3.0000,  4.5000,  6.0000]),\n",
       " tensor([   0,  171,  342,  512,  682,  853, 1023]),\n",
       " tensor([-2.9956, -1.4927,  0.0103,  1.5044,  2.9985,  4.5015,  5.9956]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(-2, 5) * 1.5\n",
    "x, discretize(x), undiscretize(discretize(x), x.min(), x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e4895-b57d-480a-8620-c25887a285ff",
   "metadata": {},
   "source": [
    "Think about how you would tokenize and batch the examples below?\n",
    "\n",
    "Keep in mind: samples might have different numbers of episodes and different numbers of tokens for a given key ('mission', 'image', 'action', etc...)\n",
    "\n",
    "- One sample might have 19 episodes with a mission of \"reach the goal\".\n",
    "- Another sample might have 12 episodes with a mission of \"find the green key\".\n",
    "- Another might have 17 episodes where the first 10 have a mission of \"find the green key\" and the last 7 have a mission of \"exit through the green door\".\n",
    "\n",
    "All of that means you're going to have to pad along several different dimensions.\n",
    "\n",
    "Note that we can't stack these until both pad _and_ embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c59746ce-f512-4d0f-a173-57f575fc9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        # Continuous/Discrete/Text looks like this:\n",
    "        #\n",
    "        #                                 Episodes\n",
    "        #                                 |  Tokens\n",
    "        #                                 |  |  Channels\n",
    "        #                                 |  |  |\n",
    "        'mission': torch.arange(2*3).view(2, 3, 1),\n",
    "        # Images look like this:\n",
    "        #\n",
    "        #                                  Episodes\n",
    "        #                                  |  Height\n",
    "        #                                  |  |  Width\n",
    "        #                                  |  |  |  Channels\n",
    "        #                                  |  |  |  |\n",
    "        'image': torch.randn(2*7*7*3).view(2, 7, 7, 3),\n",
    "        'action': torch.arange(2*1).view(2, 1, 1),\n",
    "    },\n",
    "    {\n",
    "        'mission': torch.arange(3*4).view(3, 4, 1),\n",
    "        'image': torch.randn(2*7*7*3).view(2, 7, 7, 3),\n",
    "        'action': torch.arange(3*1).view(3, 1, 1),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91ef37e2-58be-466a-adf0-44d39bc919db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(text_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20954d48-8ed2-481c-8073-2fadfbc50bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 1]),\n",
       " tensor([[[50256],\n",
       "          [15496],\n",
       "          [   11],\n",
       "          [  995],\n",
       "          [    0],\n",
       "          [50256]]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_text(\"Hello, world!\")\n",
    "tokens.shape, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cc05924-72a4-4bd2-adb7-c3eab33cee94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed210e50-f2ef-48d0-832b-c8b10e981d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 1]),\n",
       " tensor([[[50257],\n",
       "          [50258],\n",
       "          [50259],\n",
       "          [50260]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_discrete([0, 1, 2, 3])\n",
    "tokens.shape, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "104a43c2-d43b-416c-bac9-2b8d3679502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_discrete(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf677340-8c44-4a5a-bcaf-55f4347d609f",
   "metadata": {},
   "source": [
    "## Image prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc34a82f-ba64-410a-800a-de6a65db3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "denormalize = transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.255], [1/0.229, 1/0.224, 1/0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1924e6c-607b-4d5a-b693-35ce0e2f10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.RandomResizedCrop((192, 192), (1.0, 1.0)),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4444f2-a1eb-47d3-8c1d-3ba6313a00b9",
   "metadata": {},
   "source": [
    "## Padding and slicing to fit context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d017525f-2de1-45c7-b204-2989203399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f664c20-8db2-4651-a0bf-534ca61933d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These next 5 functions are helpers for when we need have a sample with\n",
    "# a large number of episodes and creating a sequence from all of them would\n",
    "# be larger than our context window.\n",
    "#\n",
    "# These helpers pick a random index for an episode from the sample\n",
    "# and then slice up to the greatest index that's within our max sequence length.\n",
    "\n",
    "def episode_num_tokens(sample):\n",
    "    return sum([len(v[0]) for v in sample.values()])\n",
    "\n",
    "def sample_num_tokens(sample):\n",
    "    return episode_num_tokens(sample) * next(iter(sample.values())).size(0)\n",
    "\n",
    "def sequence_episode_capacity(sequence_length, sample):\n",
    "    return sequence_length // episode_num_tokens(sample)\n",
    "\n",
    "def random_episode_start_index(sequence_length, sample):\n",
    "    cap = min(next(iter(sample.values())).size(0), sequence_episode_capacity(sequence_length, sample))\n",
    "    return random.randint(0, cap)\n",
    "\n",
    "def slice_to_context_window(sequence_length, sample):\n",
    "    result = OrderedDict()\n",
    "    n = random_episode_start_index(1024, sample)\n",
    "    m = sequence_episode_capacity(1024, sample)\n",
    "    for k in sample.keys():\n",
    "        result[k] = sample[k][n:n+m]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9b9e258-03e5-472e-b6d3-16a81d1c5171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There's a hidden depency in all of this code that `batch` is an OrderedDict.\n",
    "# The order of the keys is the order we'll use to create a sequence of observations for training.\n",
    "def pad(batch, padding_value=0):\n",
    "    padded = OrderedDict()\n",
    "    for k, v in batch[0].items():\n",
    "        episode_length = max(sample[k].size(0) for sample in batch)\n",
    "        token_length = max(sample[k].size(1) for sample in batch)\n",
    "        for sample in batch:\n",
    "            pad = (0, 0, 0, token_length - sample[k].size(1), 0, episode_length - sample[k].size(0))\n",
    "            padded[k] = padded.get(k, [])\n",
    "            padded[k].append(F.pad(sample[k], pad, value=0))\n",
    "    return OrderedDict([\n",
    "        (k, torch.stack(v))\n",
    "        for k, v in padded.items()\n",
    "    ])\n",
    "\n",
    "def mask(batch):\n",
    "    result = OrderedDict()\n",
    "    for k, v in batch[0].items():\n",
    "        episode_lengths = [sample[k].size(0) for sample in batch]\n",
    "        token_lengths = [sample[k].size(1) for sample in batch]\n",
    "        result[k] = torch.zeros(len(batch), max(episode_lengths), max(token_lengths))\n",
    "        for i in range(len(batch)):\n",
    "            result[k][i][:episode_lengths[i], :token_lengths[i]] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe876c1e-577b-438a-aad8-9e6db06164cc",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaf3de-8cc2-4941-b5e1-abe2e1c6367d",
   "metadata": {},
   "source": [
    "### The Four Rooms Dataset\n",
    "\n",
    "Each dataset will need a few customized functions to manipulate the data into something a transformer can use.\n",
    "\n",
    "In the case of the Four Rooms Dataset, that means converting a discrete description of a grid into an image. We probably could have gotten by with encoding the grid as discrete observations. But images give us spatial information thanks to the patch position encoding. Plus, it doesn't seem like it would hurt anything to have more visual data to train on.\n",
    "\n",
    "The functions you'll need for most datasets will be:\n",
    "\n",
    "- miscellanous manipulations, like the Four Rooms grid-observation to an image\n",
    "- tokenizer\n",
    "- collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e25bb39-2375-4d38-812e-6d9d4ad74259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some FourRooms/Minigrid-specific stuff to turn\n",
    "# a 7x7x3 non-pixel observation into an pixel/image observation.\n",
    "lut = np.zeros((256, 3), dtype=np.uint8)\n",
    "for idx, color_name in minigrid.core.constants.IDX_TO_COLOR.items():\n",
    "    lut[idx] = minigrid.core.constants.COLORS[color_name]\n",
    "\n",
    "def four_rooms_to_rgb(images):\n",
    "    \"\"\"Convert discrete \"image\" observations into actual images.\n",
    "    I'm expecting this will improve our image modality while not losing\n",
    "    much. The downside is we can fit less in our context window. Note:\n",
    "    We might need to overlay the color/type image (index 1) with the\n",
    "    state image (index 2), if we really don't want to lose any info.\"\"\"\n",
    "    # Apply lookup to second channel\n",
    "    return torch.from_numpy(lut[images[:, :, :, 1]]).permute(0, 3, 1, 2)    \n",
    "\n",
    "def tokenize_four_rooms(tokenizer, episode):\n",
    "    mission_tokens = [tokenizer.encode_text(mission) for mission in episode.observations[\"mission\"][:-1]]\n",
    "    direction_tokens = [tokenizer.encode_discrete(direction) for direction in episode.observations[\"direction\"][:-1]]\n",
    "    image = episode.observations[\"image\"][:-1]\n",
    "    image = four_rooms_to_rgb(image)\n",
    "    image_tokens = [tokenizer.encode_image(image) for image in image_transform(image)]\n",
    "    action_tokens = [tokenizer.encode_discrete(action, is_action=True) for action in episode.actions]\n",
    "    return OrderedDict({\n",
    "        'mission': torch.concat(mission_tokens),\n",
    "        'direction': torch.concat(direction_tokens), \n",
    "        'image': torch.concat(image_tokens),\n",
    "        'action': torch.concat(action_tokens),\n",
    "    })\n",
    "\n",
    "def four_rooms_collate_fn(batch, sequence_length=1024):\n",
    "    sliced = [slice_to_context_window(sequence_length, sample) for sample in batch]\n",
    "    padded = pad(sliced)\n",
    "    return padded, mask(sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53b3c564-1433-4a6e-acf5-e65b7d5ea6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataset = minari.load_dataset('D4RL/minigrid/fourrooms-v0', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7a79795-1834-4aaf-8953-e46ffeb6d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataset_xf = TransformDataset(four_rooms_dataset, partial(tokenize_four_rooms, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27550b86-8858-43a2-b1f4-08d63e676a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 5, 1]), torch.Size([19, 1, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset_xf[0]['mission'].shape, four_rooms_dataset_xf[0]['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ae7a1d6-68c0-4226-83c7-965966bd0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [four_rooms_dataset_xf[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "547e6708-0b64-4439-8f8a-8ff79c27b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded, masked = four_rooms_collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cfed524-ccd7-4bd1-bbd5-3065c5e411ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 6, 5, 1]),\n",
       " torch.Size([4, 6, 1, 1]),\n",
       " torch.Size([4, 6, 144, 768]),\n",
       " torch.Size([4, 6, 1, 1])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[padded[p].shape for p in padded.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eda8f1d-3695-4ccd-9fbb-bc8d5770bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 6, 5]),\n",
       " torch.Size([4, 6, 1]),\n",
       " torch.Size([4, 6, 144]),\n",
       " torch.Size([4, 6, 1])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[masked[p].shape for p in masked.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "974984d3-6241-4396-8ea0-d30a7238e9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['mission', 'direction', 'image', 'action'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5afd4-ce5e-4d8c-9ff0-b457afb66d73",
   "metadata": {},
   "source": [
    "#### Exploring the Four Rooms dataset - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa51811f-0154-4d58-b5db-2319ce923c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(12, 4))\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i][j].imshow(four_rooms_to_rgb(four_rooms_dataset[0].observations['image'][[i*4+j]])[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebbfc683-8cca-4d8f-bb67-a4e46b9a35a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 7, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset[0].observations['image'][[i]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9512212d-88aa-42c6-9af1-7aef69feda92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x770eba060740>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patches = four_rooms_dataset_xf[0]['image']\n",
    "plt.imshow(tokenizer.decode_image(patches).permute(0, 2, 3, 1)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36807492-4b82-40cf-a6fe-95ac1a85ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = four_rooms_dataset_xf[0]['image']\n",
    "tokenizer.decode_image(patches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81740b75-c7ff-4f7c-82e9-555708bb31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = four_rooms_dataset_xf[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27cd50ea-eb45-4a2b-997c-f2f7b5e1cedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 144, 3, 16, 16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset_xf[0]['image'].reshape(B, T, 3, 16, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a4475b2-9e7b-46d9-a63c-a8d50e56dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3, 192, 192])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_image(four_rooms_dataset_xf[0]['image']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "393498f7-a472-47c3-85ba-8160db0357c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7, 7, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset[0].observations['image'].shape\n",
    "# 20 \"episodes\" (or \"steps\" that the robot took to complete the task)\n",
    "# 7x7 grid of vision at each step\n",
    "# 3 \"channels\". NOT RGB. (object_type, object_color, object_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81834b01-30e3-48aa-affc-1c1ed2c35388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3, 7, 7]),\n",
       " tensor([[[255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 255, 255, 255, 255],\n",
       "          [100, 100, 100, 100, 100, 100, 100]],\n",
       " \n",
       "         [[  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0,   0,   0,   0,   0],\n",
       "          [100, 100, 100, 100, 100, 100, 100]],\n",
       " \n",
       "         [[  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0,   0,   0,   0,   0],\n",
       "          [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = four_rooms_to_rgb(four_rooms_dataset[0].observations['image'])\n",
    "images.shape, images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4c61629-dae3-4d61-a723-6bebd48eeb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x770eb9fd22d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b12eac3e-ce3c-4e44-a196-1e4be66d3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPythonImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15f1cc1c-4775-418b-a797-60aa4e21d426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=7x7>,\n",
       " <PIL.Image.Image image mode=RGB size=7x7>,\n",
       " <PIL.Image.Image image mode=RGB size=7x7>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting them to PIL Images gives us a convenient way to save the images as a GIF.\n",
    "images = four_rooms_to_rgb(four_rooms_dataset[0].observations['image'])\n",
    "images = images.permute(0, 2, 3, 1).numpy()\n",
    "images = [Image.fromarray(image) for image in images]\n",
    "images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07fd8e9d-08dc-4a90-8041-6c73fc1f734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "R0lGODlhBwAHAIEAAGRkZP8AAAAAAAAAACH/C05FVFNDQVBFMi4wAwEAAAAh+QQAFAAAACwAAAAABwAHAAAIFwADCAQgsGAAggYPJlSYEOHCgQAiSgwIACH5BAEUAAIALAAAAAAHAAcAgWRkZP8AAAAAAAAAAAgXAAUIFAgAwMCDCBMqTGhQYICHAh4GCAgAIfkEARQAAgAsAAAAAAUABwCBZGRk/wAAAAAAAAAACBcAAQgUMFBAAIICDCJUCCDhwYYMHQoICAAh+QQBFAACACwAAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwBAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwCAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwDAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwEAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwAAAAABwAHAIFkZGT/AAAAAAAAAAAIGwAFCBQYIMBAggIAKFSY8KAAgwAOQpTYcKDBgAAh+QQBFAACACwAAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAgAsAQAEAAIAAwCBZGRk/wAAAAAAAAAACAcAAwAQKDAgACH5BAEUAAIALAIABAACAAMAgWRkZP8AAAAAAAAAAAgHAAMAECgwIAAh+QQBFAACACwDAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAwAsAAADAAYABACBAP8AZGRk/wAAAAAACA8AAQwYSJCggAAFDyYMEBAAIfkEARQAAwAsAAADAAcABACBAP8AZGRk/wAAAAAACBIABQAYQLCgQQEBDA4QoHDhgIAAIfkEARQAAwAsAQADAAYAAgCBAP8AZGRk/wAAAAAACAsABQAYQLBgQQEBAQAh+QQBFAADACwCAAMAAgABAIEA/wBkZGT/AAAAAAAIBQAFAAgIACH5BAEUAAMALAAAAwAFAAQAgQD/AGRkZP8AAAAAAAgQAAMMGCAAgMCBAw4OVDggIAAh+QQBFAADACwAAAIABgAFAIEA/wBkZGT/AAAAAAAIFAAFDBg4UECAggAMEhygkGDDgQEBACH5BAEUAAIALAEAAgAFAAUAgWRkZP8AAAAAAAAAAAgSAAMIGCggAICBAQwSVIjw4MCAADs=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 192,
       "width": 192
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "# But there's a better way!\n",
    "buffer = io.BytesIO()\n",
    "images[0].save(\n",
    "    buffer,\n",
    "    format='GIF',\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    duration=200,\n",
    "    loop=0,\n",
    ")\n",
    "buffer.seek(0)\n",
    "display(IPythonImage(data=buffer.getvalue(), width=192, height=192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8aadf8b5-cc36-4ff7-a40e-54c11a775343",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataloader = DataLoader(four_rooms_dataset_xf, batch_size=4, collate_fn=four_rooms_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee444ddc-34c6-4c48-ae4f-9965fbec6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(four_rooms_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1418162-447f-4551-9502-9e22524bf8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 5, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['mission'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb587868-2ac7-4476-b7d8-eafaa2da4c24",
   "metadata": {},
   "source": [
    "### Visual Question Answering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29a813e2-bf71-4f7c-869a-313007512c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset = datasets.load_dataset(\"eihli/micro-ok-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6a70f2c-dfb5-4dc2-84f5-c5e24e047b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_vqa(tokenizer, sample):\n",
    "    question = [tokenizer.encode_text(sample[\"question\"])]\n",
    "    image = [tokenizer.encode_image(image_transform(pil_to_tensor(sample[\"image\"])))]\n",
    "    answer = [tokenizer.encode_text(random.choice(sample[\"answers\"])[\"answer\"])]\n",
    "    return OrderedDict({\n",
    "        'question': torch.stack(question),\n",
    "        'image': torch.stack(image),\n",
    "        'answer': torch.stack(answer),\n",
    "    })\n",
    "\n",
    "def vqa_collate_fn(batch, sequence_length=1024):\n",
    "    sliced = [slice_to_context_window(sequence_length, sample) for sample in batch]\n",
    "    padded = pad_tokens(sliced)\n",
    "    masked = mask(batch)\n",
    "    return padded, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e183723b-bb11-4f82-a545-3e821da023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = vqa_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81fb8e8a-425f-45eb-bb0b-2d4cf132f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_image(image_transform(pil_to_tensor(sample[\"image\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df27a94c-26cb-4304-8890-a7b1daf988a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 144, 768]),\n",
       " tensor([[[-0.2378, -0.2437, -0.2390,  ...,  0.1854,  0.1832,  0.1849],\n",
       "          [-0.2446, -0.2466, -0.2453,  ...,  0.2264,  0.2325,  0.2391],\n",
       "          [-0.1818, -0.1153, -0.0956,  ...,  0.2149,  0.2101,  0.2130],\n",
       "          ...,\n",
       "          [ 0.0385,  0.0600,  0.0706,  ...,  0.2237,  0.2288,  0.2367],\n",
       "          [ 0.0707,  0.0894,  0.1001,  ...,  0.2478,  0.2362,  0.0630],\n",
       "          [-0.0377, -0.0938, -0.1630,  ...,  0.1883,  0.1839,  0.1875]]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac887f91-9e9c-4c9b-885d-1a9c2044385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset_xf = TransformDataset(vqa_dataset[\"train\"], partial(tokenize_vqa, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ab6f147-d35b-4fbe-808f-529dfc037136",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = four_rooms_dataset_xf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "991e3e5c-47f4-4c2f-9b08-82f8a6d3020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 12, 1]),\n",
       " torch.Size([1, 1, 144, 768]),\n",
       " 'pony tail',\n",
       " 'What is the hairstyle of the blond called?')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = vqa_dataset_xf[0]\n",
    "(\n",
    "    sample['question'].shape, \n",
    "    sample['image'].shape, \n",
    "    tokenizer.decode_text(sample['answer'][0]), \n",
    "    tokenizer.decode_text(sample['question'][0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ff95e88-ac51-47bf-9fc9-f40e89853012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[50256], [79], [1647], [7894], [50256]]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['answer'][0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d240a6c-979a-432f-9f53-6d48ac4a1237",
   "metadata": {},
   "source": [
    "### Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "175455e5-340b-4d4c-8132-bfd538eae275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_shakespeare_dataset():\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    shakespeare_filepath = Path(temp_dir)/\"shakespeare.txt\"\n",
    "    if not os.path.exists(shakespeare_filepath):\n",
    "        data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "        with open(shakespeare_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(requests.get(data_url).text)\n",
    "    \n",
    "    with open(shakespeare_filepath, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # Split the dataset into each character's lines.\n",
    "    # Continue taking lines until you have at least 250 words in the sample.\n",
    "    # Add that sample to the dataset.\n",
    "    characters_lines = re.split(r\"\\n\\s*\\n\", data.strip())\n",
    "    MIN_WORDS_PER_BATCH = 250\n",
    "    sample = [characters_lines[0]]\n",
    "    num_words_in_sample = len(characters_lines[0].split())\n",
    "    text_dataset = []\n",
    "    i = 1\n",
    "    while i < len(characters_lines):\n",
    "        if num_words_in_sample > MIN_WORDS_PER_BATCH:\n",
    "            text_dataset.append(\"\\n\\n\".join(sample))\n",
    "            num_words_in_sample -= len(sample[0].split())\n",
    "            sample = sample[1:]\n",
    "        sample += [characters_lines[i]]\n",
    "        num_words_in_sample += len(characters_lines[i].split())\n",
    "        i += 1\n",
    "\n",
    "    return text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb50e5b2-287f-4ddc-bd73-a0cdd80a3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_dataset = acquire_shakespeare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b66f667-de6b-4f48-a9a4-1cad8d3a3dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 7184\n",
      "Character length of first 3 samples: [1632, 1688, 1891]\n",
      "\n",
      "First 80 characters of first sample:\n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in the dataset: {len(shakespeare_dataset)}\")\n",
    "print(f\"Character length of first 3 samples: {[len(x) for x in shakespeare_dataset[:3]]}\\n\")\n",
    "print(f\"First 80 characters of first sample:\\n\\n{shakespeare_dataset[0][:80]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3a900a0-8e9d-4e4f-979b-537fb4a2f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_shakespeare(tokenizer, sample):\n",
    "    text = [tokenizer.encode_text(sample)]\n",
    "    return OrderedDict({\n",
    "        'text': torch.concat(text),\n",
    "    }) \n",
    "\n",
    "def shakespeare_collate_fn(batch, sequence_length=1024):\n",
    "    padded = pad(batch)\n",
    "    masked = mask(batch)\n",
    "    return padded, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "144d4d60-d742-494d-afc2-b6a9edf7b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_dataset_xf = TransformDataset(shakespeare_dataset, partial(tokenize_shakespeare, tokenizer))\n",
    "shakespeare_dataloader = DataLoader(shakespeare_dataset_xf, batch_size=4, collate_fn=shakespeare_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9824741b-1c2f-4f64-a72d-421a61ead312",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [shakespeare_dataset_xf[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3211f890-46ad-4962-93fc-946ab25c7b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 454, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41784696-07e2-419f-a53b-e5529262ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched, masked = next(iter(shakespeare_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97b516fe-abbd-41a8-a7c4-6016ad08a9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['text']),\n",
       " torch.Size([4, 1, 522, 1]),\n",
       " torch.Size([4, 1, 522]),\n",
       " OrderedDict([('text',\n",
       "               tensor([[[1., 1., 1.,  ..., 0., 0., 0.]],\n",
       "               \n",
       "                       [[1., 1., 1.,  ..., 0., 0., 0.]],\n",
       "               \n",
       "                       [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "               \n",
       "                       [[1., 1., 1.,  ..., 0., 0., 0.]]]))]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched.keys(), batched['text'].shape, masked['text'].shape, masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61255f6-e8cc-46fe-b4a6-52045dce7c77",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea972ae4-4323-4131-9af2-a4509dc4bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06b6d575-4b9d-492c-bfc1-62eb9047d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding = ResNetV2(layers=[3, 4, 6, 3], num_classes=EMBEDDING_DIMS)\n",
    "lookup_embedding = torch.nn.Embedding(tokenizer.n_text + tokenizer.n_discrete + tokenizer.n_modalities, EMBEDDING_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6728532-c3cc-45a1-86e1-4f7d238d7a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e24fe134-9d36-4648-87a2-fc6bce3ab648",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, masked = next(iter(four_rooms_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1635918-e327-4301-b480-048a347d0476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 144, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tokens = batch['image']\n",
    "image_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e9d7cce-b6c8-4375-8a82-a112a48f285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, E, T, C = image_tokens.shape\n",
    "patch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83af0d4f-e30f-4583-8d67-ff46fd664776",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_tokens = image_tokens.view(B*E*T, 3, patch_size, patch_size)\n",
    "patch_embeddings = image_embedding(patch_tokens).view(B, E, T, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bfed7ccc-aff9-4d4e-bce9-e47687c74866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3456, 3, 16, 16])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "96afd113-5b85-4e39-a5f6-9e97aca6db0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 144, 512])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99712d93-6500-41ba-92c0-fe6bbf5ebfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 5, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_tokens = batch['mission']\n",
    "mission_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4212d2b-43e2-4ec3-9641-98bbdb6908cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, E, T, C = mission_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfdf2c63-77d0-4ddd-bf4c-1887254ac3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_tokens.view(B*E*T, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6058d0f2-edfd-45ae-84a2-4960f73f6106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 5, 512])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_embeddings = lookup_embedding(mission_tokens).view(B, E, T, -1)\n",
    "mission_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ca05665-94b3-466e-b208-283e7ab35f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "@dataclass\n",
    "class Embedder:\n",
    "    tokenizer: Tokenizer\n",
    "    lookup_embedding: Callable\n",
    "    image_embedding: Callable\n",
    "\n",
    "    def embed(self, data):\n",
    "        B, E, T, C = data.shape\n",
    "        if self.tokenizer.is_image(data):\n",
    "            #                                         (C,  P,  P)\n",
    "            return self.image_embedding(data.view(B*E*T, 3, 16, 16)).view(B, E, T, -1)\n",
    "        else:\n",
    "            return self.lookup_embedding(data.view(B*E*T)).view(B, E, T, -1)\n",
    "\n",
    "def sequence(embedder, batch, mask, sequence_length=1024):\n",
    "    embeddings = torch.concat([embedder.embed(v) for k, v in batch.items()], dim=2)\n",
    "    masks = torch.concat([v for _, v in mask.items()], dim=2)\n",
    "    B, E, T, C = embeddings.shape\n",
    "    embeddings = embeddings.view(B, E*T, C)\n",
    "    masks = masks.view(B, E*T)\n",
    "    return (\n",
    "        F.pad(embeddings, (0, 0, 0, sequence_length - embeddings.size(1), 0, 0), value=0),\n",
    "        F.pad(masks, (0, sequence_length - embeddings.size(1), 0, 0), value=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58fb0974-ea02-43f4-b510-35d38f4a1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(tokenizer, lookup_embedding, image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39e32244-5265-49ac-ac3d-2c09f9c68b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 5, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4eac035d-addd-476f-9876-f5b85d361d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 5, 512])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.embed(mission_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8a50773-b7d1-444e-9d31-a36d40b97932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 144, 512])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.embed(image_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c7f8d099-e4fb-4cdd-917b-a5385382bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, masks = next(iter(four_rooms_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9aade3ed-fa01-4e7a-81b2-afb495b46ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 6, 5, 1]), torch.Size([4, 6, 5]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['mission'].shape, masks['mission'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8398e70b-ff03-42cb-8324-70d4a8a9c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.concat([embedder.embed(v) for k, v in batch.items()], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9a399d5e-5534-4b34-8999-c7970e96af43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 151, 512])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bc7ef49-43f2-442f-a8c6-da96efc341a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 151])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([v for v in masks.values()], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "166a919a-4ef4-45d7-a9c2-a7ae22aeffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 906, 512])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, E, T, C = embeddings.shape\n",
    "embeddings.view(B, E*T, C).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0056aad-a46f-46b2-9348-ebc3d7dc8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 144])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "305e024b-326d-436e-818b-65f699a65a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(collections.OrderedDict, collections.OrderedDict)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch), type(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72e9fbd2-a329-42ea-a257-f7a81e981364",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, msk = sequence(embedder, batch, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4cfdb8af-ff02-475d-9087-be820be7d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1024, 512]), torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape, msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c5bfc16-0f30-4eac-882c-cf50b36d2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bch, msk = sequence(embedder, batch, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bffa6f09-3c7f-4e74-a98e-5f5201d17b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1024, 512]), torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bch.shape, msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "164bd4e0-bb84-412c-a75e-e653ba01962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched, masked = next(iter(shakespeare_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7caabbce-4b06-4d42-896d-19ea2a9a6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, msk = sequence(embedder, batched, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75c50f8d-f05f-49f0-802b-64d586fb6442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1024, 512]), torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape, msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e54557f1-9b75-4ae2-8666-0af79567f68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046c952-05c4-4b58-a1bc-36298c25c7c7",
   "metadata": {},
   "source": [
    "## Continuous Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6fb210a3-c7b6-4565-ab21-d70f4e75ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointmaze_dataset = minari.load_dataset('D4RL/pointmaze/open-v2', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6aaa335-bbd9-4e70-991e-35008e35a88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['achieved_goal', 'desired_goal', 'observation'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointmaze_dataset[0].observations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2c6529cf-ea02-4ceb-9df2-7e93f2af7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_pointmaze(tokenizer, sample):\n",
    "    goal_tokens = [tokenizer.encode_continuous(goal) for goal in sample.observations[\"desired_goal\"][:-1]]\n",
    "    action_tokens = [tokenizer.encode_continuous(action, is_action=True) for action in sample.actions]\n",
    "    return OrderedDict({\n",
    "        'goal': torch.concat(goal_tokens),\n",
    "        'action': torch.concat(action_tokens), \n",
    "    })\n",
    "\n",
    "def pointmaze_collate_fn(batch, sequence_length=1024):\n",
    "    sliced = [slice_to_context_window(sequence_length, sample) for sample in batch]\n",
    "    padded = pad(sliced)\n",
    "    if padded['goal'].size(1) == 0:\n",
    "        pdb.set_trace()\n",
    "    return padded, mask(sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8df41dff-1460-4455-86c1-aad72a899639",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointmaze_dataset_xf = TransformDataset(pointmaze_dataset, partial(tokenize_pointmaze, tokenizer))\n",
    "pointmaze_dataloader = DataLoader(pointmaze_dataset_xf, batch_size=4, collate_fn=pointmaze_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4b67ceba-94ac-4b2f-81eb-65d4b7327314",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(pointmaze_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4fc3017a-8fc2-4d14-bd93-3749ccf7728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched, masked = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "faa56263-221c-4cb7-ab17-0cd65e14a09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 157, 2, 1]), torch.Size([4, 157, 2, 1])]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for v in batched.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "188ddf19-c384-426f-b298-598d38b22f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [pointmaze_dataset_xf[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d605ed92-80d3-4a13-b3a6-2cc23f3d6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].values();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d6652cf-4919-42a3-a287-8094913eca3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 72, 2, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointmaze_collate_fn(batch)[0]['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050993e-dabe-4a68-af7a-f8087bee0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_dataset_xf = TransformDataset(shakespeare_dataset, partial(tokenize_shakespeare, tokenizer))\n",
    "shakespeare_dataloader = DataLoader(shakespeare_dataset_xf, batch_size=4, collate_fn=shakespeare_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b9bbc-f76a-40d0-82e7-d77f2f971632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156f450-b55f-4a54-9a15-15fe741e81c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fd3b4-e5ca-46cb-9044-5d14b06c81b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc787bc-596d-444d-ae93-82c2d3e3f068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ef119-918b-4cf9-b6aa-f335a76de813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33872971-88d2-4489-bf40-8f5fd56b3342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1022d2-bc04-4deb-9ca1-c319ff619470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
