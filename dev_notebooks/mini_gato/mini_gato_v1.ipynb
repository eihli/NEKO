{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd656399-9092-49f2-9367-604bdeccb25c",
   "metadata": {},
   "source": [
    "# MiniGato\n",
    "\n",
    "From the paper [A Generalist Agent](https://arxiv.org/abs/2205.06175).\n",
    "\n",
    "The paper doesn't introduce a new architecture. Instead, the paper is all about tokenizing, embedding, and sequencing data from multiple modalities (text, image, proprioception) in such a way that it can be learned by a transformer.\n",
    "\n",
    "Reproducing the paper is more of a software design exercise than an ML research exercise. How would you structure the data manipulation code – the tokenization, embedding, and sequencing of different modalities – in a way that's correct, easy to understand and extend, and performant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97948900-a02f-44cb-b793-dd8fc1ad85e3",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Just grouping and hiding these to avoid noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4141fa3f-3a9a-4cc7-9b61-743cfc9c1b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mini_gato.util' from '/home/eihli/src/mini_gato/mini_gato/util.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mini_gato\n",
    "import mini_gato.util\n",
    "import importlib\n",
    "importlib.reload(mini_gato.util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa349ff-310a-4f88-83c3-ab28a8e553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import cycle\n",
    "import math\n",
    "import pdb\n",
    "import random\n",
    "from typing import List\n",
    "from dataclasses import dataclass, fields\n",
    "import datasets\n",
    "from einops import rearrange\n",
    "from functools import partial\n",
    "from mini_gato.nano_gpt import GPT, GPTConfig\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import minari\n",
    "from mini_gato.util import (\n",
    "    tensor_as_gif, TransformDataset,\n",
    "    images_to_patches, patches_to_images, normalize_to_between_minus_one_plus_one,\n",
    "    apply_along_dimension, mu_law_decode, mu_law_encode,\n",
    "    interleave, deinterleave,\n",
    ")\n",
    "import minigrid.core\n",
    "from timm.models.resnetv2 import ResNetV2\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaea521b-74a2-41ee-8596-39905efc1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave tensors a, b, and c, such that\n",
    "# the result is `[[1, 2, 3, 9, 8, 7, 5, 5, 5, 5], [4, 5, 6, 9, 8, 7, 6, 5, 4, 6, 6, 6, 6], ...]\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[9, 8, 7], [6, 5, 4]])\n",
    "c = torch.tensor([[5, 5, 5, 5], [6, 6, 6, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a090e-2a37-449a-8309-4046b386a5f2",
   "metadata": {},
   "source": [
    "## Tokenization [§ 2.1](https://arxiv.org/pdf/2205.06175)\n",
    "\n",
    "> There are infinite possible ways to transform data into tokens, including directly using the raw underlying byte stream.\n",
    "\n",
    "We're going to start off with a certain set of tokenization strategies for a certain set of modalities. We might want to expand that in the future. When that happens, I don't want to have to edit code in the PyTorch Module that implements our model code. I'd rather be able to add a new class of modality that implements a \"tokenization\" signature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee1280-36d7-4aa3-9155-81b827f25690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fba779b-9555-4f69-964a-0f96a9706a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataset = minari.load_dataset('D4RL/minigrid/fourrooms-v0', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30dcee9-7c75-4e19-afe9-4539444444f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpisodeData(id=0, total_steps=19, observations={direction: ndarray of shape (20,) and dtype int64, image: ndarray of shape (20, 7, 7, 3) and dtype uint8, mission: ['reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal']}, actions=ndarray of shape (19,) and dtype int64, rewards=ndarray of 19 floats, terminations=ndarray of 19 bools, truncations=ndarray of 19 bools, infos=dict with the following keys: [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df34524-18e2-44fe-92fe-02089ce1fe95",
   "metadata": {},
   "source": [
    "## Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de9fd68-6189-47c7-badd-1789ef1af85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Modality:\n",
    "    origin: any\n",
    "    tokens: torch.Tensor\n",
    "    targets: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "    embeddings: torch.Tensor = torch.tensor([])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{type(self).__name__}(\\n\\t{self.origin!r}\\n\\t{self.tokens!r}\\n\\t{self.targets!r}\\n\\t{self.attention_mask!r}\\n\\t{self.embeddings!r}\\n)\"\n",
    "        \n",
    "    def size(self, *args, **kwargs):\n",
    "        return self.tokens.size(*args, **kwargs)\n",
    "\n",
    "    def to(self, device):\n",
    "        \"\"\"Return new instance of class with all fields moved to device.\"\"\"\n",
    "        return type(self)(\n",
    "            tokens=type(self.tokens)(self.tokens.to(device)),\n",
    "            targets=type(self.targets)(self.targets.to(device)),\n",
    "            attention_mask=type(self.attention_mask)(self.attention_mask.to(device)),\n",
    "            embeddings=type(self.embeddings)(self.embeddings.to(device)),\n",
    "        )\n",
    "\n",
    "    def clone(self):\n",
    "        return type(self)(\n",
    "            tokens=type(self.tokens)(self.tokens.clone()),\n",
    "            targets=type(self.targets)(self.targets.clone()),\n",
    "            attention_mask=type(self.attention_mask)(self.attention_mask.clone()),\n",
    "            embeddings=type(self.embeddings)(self.embeddings.clone()),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e0d978-ee42-474a-9d5e-c99b98066dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modality(\n",
       "\t'foo'\n",
       "\ttensor(1)\n",
       "\ttensor(2)\n",
       "\ttensor(3)\n",
       "\ttensor([])\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Modality('foo', torch.tensor(1), torch.tensor(2), torch.tensor(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49984121-a615-4851-abb9-bb8f8e2ed906",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25e4b36-f436-462a-ade7-ea6a9195bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Series:\n",
    "    def __len__(self):\n",
    "        #       number of episodes * number of tokens per episode\n",
    "        return sum(getattr(self, field.name).tokens.size(0) * getattr(self, field.name).tokens.size(1) for field in fields(self))\n",
    "\n",
    "    def n_modalities(self):\n",
    "        return len(fields(self))\n",
    "\n",
    "@dataclass\n",
    "class FourRoomsSeries(Series):\n",
    "    mission: Modality\n",
    "    direction: Modality\n",
    "    image: Modality\n",
    "    action: Modality\n",
    "\n",
    "@dataclass\n",
    "class GenericVQASeries(Series):\n",
    "    question: Modality\n",
    "    image: Modality\n",
    "    answer: Modality\n",
    "\n",
    "@dataclass\n",
    "class GenericTextSeries(Series):\n",
    "    text: Modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451e2df-6d24-48ca-b235-b9b47f4354e9",
   "metadata": {},
   "source": [
    "Sweet. Now we can index into a series as if it were sequenced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54865902-afdd-4350-ad97-b153f800ac8e",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a737e1f2-e731-4ac0-a333-50712ef1b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212772e6-aa62-4f51-b04b-42d4c5c59638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c86484-c423-4e61-b446-86155403984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(batch, padding_value=0):\n",
    "    padded = defaultdict(list)    \n",
    "    for k, v in batch[0].items():\n",
    "        max_tokens = max([sample[k].size(1) for sample in batch])\n",
    "        for sample in batch:\n",
    "            if len(sample[k].shape) == 2:\n",
    "                pad = (0, max_tokens - sample[k].size(1), 0, 0)\n",
    "            else:\n",
    "                pad = (0, 0, 0, max_tokens - sample[k].size(1), 0, 0)\n",
    "            padded[k].append(F.pad(sample[k], pad, value=0))\n",
    "    results = []\n",
    "    for _ in range(len(batch)):\n",
    "        results.append({})\n",
    "    for k, vs in padded.items():\n",
    "        for i in range(len(batch)):               \n",
    "            results[i][k] = padded[k][i]\n",
    "    return results\n",
    "\n",
    "def pad_sequence(batch, sequence_length=1024, padding_value=0):\n",
    "    padded = defaultdict(list)\n",
    "    for k, v in batch[0].items():\n",
    "        for sample in batch:\n",
    "            if len(sample[k].shape) == 2:\n",
    "                pad = (0, 0, 0, sequence_length - sample[k].size(0))\n",
    "            else:\n",
    "                pad = (0, 0, 0, 0, 0, sequence_length - sample[k].size(0))\n",
    "            padded[k].append(F.pad(sample[k], pad, value=0))\n",
    "    results = []\n",
    "    for _ in range(len(batch)):\n",
    "        results.append({})\n",
    "    for k, vs in padded.items():\n",
    "        for i in range(len(batch)):\n",
    "            results[i][k] = padded[k][i]\n",
    "    return results\n",
    "\n",
    "def mask(batch):\n",
    "    if len(batch) == 0:\n",
    "        return []\n",
    "    result = {}\n",
    "    for k, v in batch[0].items():\n",
    "        n_episodes = [sample[k].size(0) for sample in batch]\n",
    "        n_tokens = [sample[k].size(1) for sample in batch]\n",
    "        result[k] = torch.zeros(len(batch), max(n_episodes), max(n_tokens))\n",
    "        for i in range(result[k].size(0)):\n",
    "            result[k][i][:n_episodes[i], :n_tokens[i]] = 1\n",
    "    return result\n",
    "\n",
    "batch = [\n",
    "    {\n",
    "        'mission': torch.arange(2*3).view(2, 3),\n",
    "        'image': torch.randn(2*7*7*3).view(2, 7, 7, 3),\n",
    "    },\n",
    "    {\n",
    "        'mission': torch.arange(3*4).view(3, 4),\n",
    "        'image': torch.randn(2*7*7*3).view(2, 7, 7, 3),\n",
    "    },\n",
    "]\n",
    "\n",
    "padded = pad_tokens(batch)\n",
    "padded = pad_sequence(padded, sequence_length=3)\n",
    "masked = mask(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c096f3-77c0-469a-ac06-d00a1924a210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0, 1, 2, 0],\n",
       "          [3, 4, 5, 0],\n",
       "          [0, 0, 0, 0]]),\n",
       "  tensor([[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]])],\n",
       " {'mission': tensor([[[1., 1., 1., 0.],\n",
       "           [1., 1., 1., 0.],\n",
       "           [0., 0., 0., 0.]],\n",
       "  \n",
       "          [[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]]]),\n",
       "  'image': tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1., 1., 1.]]])})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p['mission'] for p in padded], masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac918986-75da-4d73-b1a9-14d22fd38f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mission', 'image'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff89060-18a8-44f1-94cb-ab87d72d90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    TEXT = 0\n",
    "    IMAGE = 1\n",
    "    DISCRETE = 2\n",
    "    CONTINUOUS = 3\n",
    "\n",
    "    def __init__(self, text_tokenizer):\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.n_text = text_tokenizer.n_vocab\n",
    "        self.n_discrete = 1024\n",
    "        self.eod_token = 1023\n",
    "        self.n_modalities = 1024\n",
    "        self.modalities = torch.arange(self.n_modalities) + self.n_text + self.n_discrete\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        return self.modalities[self.TEXT].unsqueeze(0), torch.tensor(self.text_tokenizer.encode(text))\n",
    "\n",
    "    def decode_text(self, tokens):\n",
    "        if isinstance(tokens, torch.Tensor):\n",
    "            tokens = tokens.tolist()\n",
    "        return self.text_tokenizer.decode(tokens)\n",
    "\n",
    "    def encode_discrete(self, discrete):\n",
    "        return self.modalities[self.DISCRETE].unsqueeze(0), torch.tensor([discrete + self.n_text])\n",
    "\n",
    "    def decode_discrete(self, tokens):\n",
    "        if isinstance(tokens, torch.Tensor):\n",
    "            tokens = tokens.tolist()\n",
    "        return tokens - self.n_text\n",
    "\n",
    "    def encode_image(self, image, patch_size=16):\n",
    "        patches = images_to_patches(image, patch_size=patch_size)\n",
    "        xs = (\n",
    "            apply_along_dimension(\n",
    "                normalize_to_between_minus_one_plus_one, 1, patches\n",
    "            )\n",
    "            / math.sqrt(patch_size)\n",
    "        )\n",
    "        return self.modalities[self.IMAGE].unsqueeze(0), xs\n",
    "\n",
    "    def decode_image(self, tokens, image_shape=(3, 192, 192), patch_size=16):\n",
    "        # Lossy because I'm not saving the values used for scaling from encoding.\n",
    "        patches = (tokens * math.sqrt(patch_size) + 1) / 2\n",
    "        images = patches_to_images(patches, image_shape, patch_size=patch_size)\n",
    "        return images\n",
    "\n",
    "    def is_text(self, cls):\n",
    "        return (cls[cls.nonzero(as_tuple=True)] == self.modalities[self.TEXT]).all().item()\n",
    "\n",
    "    def is_image(self, cls):\n",
    "        return (cls[cls.nonzero(as_tuple=True)] == self.modalities[self.IMAGE]).all().item()\n",
    "\n",
    "    def is_discrete(self, cls):\n",
    "        return (cls[cls.nonzero(as_tuple=True)] == self.modalities[self.DISCRETE]).all().item()\n",
    "\n",
    "    def is_continuous(self, cls):\n",
    "        return (cls[cls.nonzero(as_tuple=True)] == self.modalities[self.CONTINUOUS]).all().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac5c589-0c40-4bc5-b02a-27738cf7b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "tokenizer = Tokenizer(text_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd204d29-7e05-40be-9ad2-cad8a9779bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([51281]), tensor([31373,    11,   995]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_text('hello, world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272cdba-f197-4712-ab28-05c983e086da",
   "metadata": {},
   "source": [
    "## Image prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc34a82f-ba64-410a-800a-de6a65db3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "denormalize = transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.255], [1/0.229, 1/0.224, 1/0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1924e6c-607b-4d5a-b693-35ce0e2f10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.RandomResizedCrop((192, 192), (1.0, 1.0)),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02973743-11b0-4593-9f33-7d0077277313",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24715654-820c-4db1-8b73-fd102b594895",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba306aa-2745-4b8e-9aac-586da899fd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def episode_num_tokens(sample):\n",
    "    return sum([len(v[0]) for v in sample.values()])\n",
    "\n",
    "def sample_num_tokens(sample):\n",
    "    return episode_num_tokens(sample) * next(iter(sample.values())).size(0)\n",
    "\n",
    "def sequence_episode_capacity(sequence_length, sample):\n",
    "    return sequence_length // episode_num_tokens(sample)\n",
    "\n",
    "def random_episode_start_index(sequence_length, sample):\n",
    "    cap = sequence_episode_capacity(sequence_length, sample)\n",
    "    return random.randint(0, cap)\n",
    "\n",
    "def slice_to_context_window(sequence_length, sample):\n",
    "    result = OrderedDict()\n",
    "    n = random_episode_start_index(1024, sample)\n",
    "    m = sequence_episode_capacity(1024, sample)\n",
    "    for k in sample.keys():\n",
    "        result[k] = sample[k][n:n+m]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70261b39-379e-4485-8da0-b89a641f59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataset = minari.load_dataset('D4RL/minigrid/fourrooms-v0', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b926cf-2990-430e-a1cd-27a4c86d65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some FourRooms/Minigrid-specific stuff to turn\n",
    "# a 7x7x3 non-pixel observation into an pixel/image observation.\n",
    "lut = np.zeros((256, 3), dtype=np.uint8)\n",
    "for idx, color_name in minigrid.core.constants.IDX_TO_COLOR.items():\n",
    "    lut[idx] = minigrid.core.constants.COLORS[color_name]\n",
    "\n",
    "def four_rooms_to_rgb(images):\n",
    "    \"\"\"Convert discrete \"image\" observations into actual images.\n",
    "    I'm expecting this will improve our image modality while not losing\n",
    "    much. The downside is we can fit less in our context window. Note:\n",
    "    We might need to overlay the color/type image (index 1) with the\n",
    "    state image (index 2), if we really don't want to lose any info.\"\"\"\n",
    "    # Apply lookup to second channel\n",
    "    return torch.from_numpy(lut[images[:, :, :, 1]]).permute(0, 3, 1, 2)    \n",
    "\n",
    "def tokenize_four_rooms(tokenizer, episode):\n",
    "    mission_cls, mission_tokens = zip(*[tokenizer.encode_text(mission) for mission in episode.observations[\"mission\"]])\n",
    "    direction_cls, direction_tokens = zip(*[tokenizer.encode_discrete(direction) for direction in episode.observations[\"direction\"]])\n",
    "    image = episode.observations[\"image\"]\n",
    "    image = four_rooms_to_rgb(image)\n",
    "    image_cls, image_tokens = zip(*[tokenizer.encode_image(image) for image in image_transform(image)])\n",
    "    action_cls, action_tokens = zip(*[tokenizer.encode_discrete(action) for action in episode.actions])\n",
    "    return OrderedDict({\n",
    "        'mission_cls': torch.stack(mission_cls[:-1]),\n",
    "        'mission': torch.stack(mission_tokens[:-1]),\n",
    "        'direction_cls': torch.stack(direction_cls[:-1]),\n",
    "        'direction': torch.stack(direction_tokens[:-1]), \n",
    "        'image_cls': torch.stack(image_cls[:-1]),\n",
    "        'image': torch.stack(image_tokens[:-1]),\n",
    "        'action_cls': torch.stack(action_cls),\n",
    "        'action': torch.stack(action_tokens),\n",
    "    })\n",
    "\n",
    "def four_rooms_collate_fn(batch, sequence_length=1024):\n",
    "    batch = [slice_to_context_window(sequence_length, sample) for sample in batch]\n",
    "    padded = pad_tokens(batch)\n",
    "    padded = pad_sequence(batch, sequence_length=sequence_length)\n",
    "    masked = mask(batch)\n",
    "    return padded, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aad30864-a91b-4726-8186-37d99bb92954",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataset_xf = TransformDataset(four_rooms_dataset, partial(tokenize_four_rooms, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "121402db-0355-4657-9fc8-9be73c948bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset = datasets.load_dataset(\"eihli/micro-ok-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "410faccd-2bd2-4f29-ad8c-eb88b0d36687",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_transform(pil_to_tensor(vqa_dataset['train'][0]['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7601da4-8c53-44b1-90fc-2e7fca88d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cls, image_tokens = zip(*[tokenizer.encode_image(image) for image in [img, img]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e74a50d1-5d63-4458-aa7b-52f65612f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[51282],\n",
       "         [51282]]),\n",
       " torch.Size([2, 144, 768]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(image_cls), torch.stack(image_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5281d651-6869-41b3-8525-d5bcd6529484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset_xf[0]['image_cls'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d24dbe7-5600-4081-aa8e-72f2a8c2f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset_xf[0]['mission'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e446e4c-bacf-432f-af49-cd95c2a9b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [four_rooms_dataset_xf[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baea1915-4634-4786-8d0d-f67d97d11b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 6, 144]), torch.Size([4, 6, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_collate_fn(batch)[1]['image'].shape, four_rooms_collate_fn(batch)[1]['direction_cls'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd95cf01-15e9-4073-8e86-cc47bc521076",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = four_rooms_collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1032c9ea-7df5-45a5-ba04-40da28d5d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0]['mission'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a60f06c-0a12-47fc-9e13-5cd1974519ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(12, 4))\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        axs[i][j].imshow(four_rooms_to_rgb(four_rooms_dataset[0].observations['image'][[i*4+j]])[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf45156b-f8c1-4f40-9366-4587c2fe5999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 7, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset[0].observations['image'][[i]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e58a39-7146-4705-94a0-441497cdd045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x774ff2e92840>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patches = four_rooms_dataset_xf[0]['image']\n",
    "plt.imshow(tokenizer.decode_image(patches).permute(0, 2, 3, 1)[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a2c166d-d723-42e4-a9e0-8bbdcec3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = four_rooms_dataset_xf[0]['image']\n",
    "tokenizer.decode_image(patches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78e50117-984f-437f-83a7-3060e4937e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = four_rooms_dataset_xf[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b1cc8e2-4bae-457d-8557-a3166d07857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 144, 3, 16, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset_xf[0]['image'].reshape(B, T, 3, 16, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51406ceb-f3cc-4231-9895-f3fd2cbb24e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3, 192, 192])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_image(four_rooms_dataset_xf[0]['image']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972cc9d-02a1-4f26-8388-937bae3a3d9b",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f55f8a-839d-4475-90e2-509770b2fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7, 7, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset[0].observations['image'].shape\n",
    "# 20 \"episodes\" (or \"steps\" that the robot took to complete the task)\n",
    "# 7x7 grid of vision at each step\n",
    "# 3 \"channels\". NOT RGB. (object_type, object_color, object_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9071db0e-3f26-49d3-9c92-9339585d2d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3, 7, 7]),\n",
       " tensor([[[255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 100, 255, 255, 255],\n",
       "          [255, 255, 255, 255, 255, 255, 255],\n",
       "          [100, 100, 100, 100, 100, 100, 100]],\n",
       " \n",
       "         [[  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0,   0,   0,   0,   0],\n",
       "          [100, 100, 100, 100, 100, 100, 100]],\n",
       " \n",
       "         [[  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0, 100,   0,   0,   0],\n",
       "          [  0,   0,   0,   0,   0,   0,   0],\n",
       "          [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = four_rooms_to_rgb(four_rooms_dataset[0].observations['image'])\n",
    "images.shape, images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7b2ced7-fca8-4efb-be0d-25a319202446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x774ff2e90c20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a011664-4cab-47b3-a28e-1f02cfb2232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPythonImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e318168-7b12-4537-b411-50f122190398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=7x7>,\n",
       " <PIL.Image.Image image mode=RGB size=7x7>,\n",
       " <PIL.Image.Image image mode=RGB size=7x7>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting them to PIL Images gives us a convenient way to save the images as a GIF.\n",
    "images = four_rooms_to_rgb(four_rooms_dataset[0].observations['image'])\n",
    "images = images.permute(0, 2, 3, 1).numpy()\n",
    "images = [Image.fromarray(image) for image in images]\n",
    "images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50117a3f-f7ba-40a0-9d55-f82c5e933496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And when you think \"save as\" you usually think \"files\".\n",
    "with open(\"/tmp/foo.gif\", \"wb\") as f:\n",
    "    images[0].save(\n",
    "        f,\n",
    "        format='GIF',\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=200,\n",
    "        loop=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cf566be-22c3-4107-842a-ee8f56a86e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And that usually means making things OS-agnostic.\n",
    "import os\n",
    "import tempfile\n",
    "temp_dir = tempfile.gettempdir()\n",
    "temp_file_path = os.path.join(temp_dir, 'foo.gif')\n",
    "with open(temp_file_path, \"wb\") as f:\n",
    "    images[0].save(\n",
    "        f,\n",
    "        format='GIF',\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=200,\n",
    "        loop=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f52253c3-2cfb-404e-bde0-c7e99c505513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "R0lGODlhBwAHAIEAAGRkZP8AAAAAAAAAACH/C05FVFNDQVBFMi4wAwEAAAAh+QQAFAAAACwAAAAABwAHAAAIFwADCAQgsGAAggYPJlSYEOHCgQAiSgwIACH5BAEUAAIALAAAAAAHAAcAgWRkZP8AAAAAAAAAAAgXAAUIFAgAwMCDCBMqTGhQYICHAh4GCAgAIfkEARQAAgAsAAAAAAUABwCBZGRk/wAAAAAAAAAACBcAAQgUMFBAAIICDCJUCCDhwYYMHQoICAAh+QQBFAACACwAAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwBAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwCAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwDAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwEAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwAAAAABwAHAIFkZGT/AAAAAAAAAAAIGwAFCBQYIMBAggIAKFSY8KAAgwAOQpTYcKDBgAAh+QQBFAACACwAAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAgAsAQAEAAIAAwCBZGRk/wAAAAAAAAAACAcAAwAQKDAgACH5BAEUAAIALAIABAACAAMAgWRkZP8AAAAAAAAAAAgHAAMAECgwIAAh+QQBFAACACwDAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAwAsAAADAAYABACBAP8AZGRk/wAAAAAACA8AAQwYSJCggAAFDyYMEBAAIfkEARQAAwAsAAADAAcABACBAP8AZGRk/wAAAAAACBIABQAYQLCgQQEBDA4QoHDhgIAAIfkEARQAAwAsAQADAAYAAgCBAP8AZGRk/wAAAAAACAsABQAYQLBgQQEBAQAh+QQBFAADACwCAAMAAgABAIEA/wBkZGT/AAAAAAAIBQAFAAgIACH5BAEUAAMALAAAAwAFAAQAgQD/AGRkZP8AAAAAAAgQAAMMGCAAgMCBAw4OVDggIAAh+QQBFAADACwAAAIABgAFAIEA/wBkZGT/AAAAAAAIFAAFDBg4UECAggAMEhygkGDDgQEBACH5BAEUAAIALAEAAgAFAAUAgWRkZP8AAAAAAAAAAAgSAAMIGCggAICBAQwSVIjw4MCAADs=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"/tmp/foo.gif\", \"rb\") as f:\n",
    "    display(IPythonImage(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d3a9679-de4a-4775-89c5-15da5452b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "R0lGODlhBwAHAIEAAGRkZP8AAAAAAAAAACH/C05FVFNDQVBFMi4wAwEAAAAh+QQAFAAAACwAAAAABwAHAAAIFwADCAQgsGAAggYPJlSYEOHCgQAiSgwIACH5BAEUAAIALAAAAAAHAAcAgWRkZP8AAAAAAAAAAAgXAAUIFAgAwMCDCBMqTGhQYICHAh4GCAgAIfkEARQAAgAsAAAAAAUABwCBZGRk/wAAAAAAAAAACBcAAQgUMFBAAIICDCJUCCDhwYYMHQoICAAh+QQBFAACACwAAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwBAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwCAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwDAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwEAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwAAAAABwAHAIFkZGT/AAAAAAAAAAAIGwAFCBQYIMBAggIAKFSY8KAAgwAOQpTYcKDBgAAh+QQBFAACACwAAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAgAsAQAEAAIAAwCBZGRk/wAAAAAAAAAACAcAAwAQKDAgACH5BAEUAAIALAIABAACAAMAgWRkZP8AAAAAAAAAAAgHAAMAECgwIAAh+QQBFAACACwDAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAwAsAAADAAYABACBAP8AZGRk/wAAAAAACA8AAQwYSJCggAAFDyYMEBAAIfkEARQAAwAsAAADAAcABACBAP8AZGRk/wAAAAAACBIABQAYQLCgQQEBDA4QoHDhgIAAIfkEARQAAwAsAQADAAYAAgCBAP8AZGRk/wAAAAAACAsABQAYQLBgQQEBAQAh+QQBFAADACwCAAMAAgABAIEA/wBkZGT/AAAAAAAIBQAFAAgIACH5BAEUAAMALAAAAwAFAAQAgQD/AGRkZP8AAAAAAAgQAAMMGCAAgMCBAw4OVDggIAAh+QQBFAADACwAAAIABgAFAIEA/wBkZGT/AAAAAAAIFAAFDBg4UECAggAMEhygkGDDgQEBACH5BAEUAAIALAEAAgAFAAUAgWRkZP8AAAAAAAAAAAgSAAMIGCggAICBAQwSVIjw4MCAADs=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 192,
       "width": 192
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"/tmp/foo.gif\", \"rb\") as f:\n",
    "    display(IPythonImage(f.read(), width=192, height=192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4919980d-071d-4e95-a76e-8fe1370de01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "R0lGODlhBwAHAIEAAGRkZP8AAAAAAAAAACH/C05FVFNDQVBFMi4wAwEAAAAh+QQAFAAAACwAAAAABwAHAAAIFwADCAQgsGAAggYPJlSYEOHCgQAiSgwIACH5BAEUAAIALAAAAAAHAAcAgWRkZP8AAAAAAAAAAAgXAAUIFAgAwMCDCBMqTGhQYICHAh4GCAgAIfkEARQAAgAsAAAAAAUABwCBZGRk/wAAAAAAAAAACBcAAQgUMFBAAIICDCJUCCDhwYYMHQoICAAh+QQBFAACACwAAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwBAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwCAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwDAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwEAAAAAgAHAIFkZGT/AAAAAAAAAAAIDAADCAgAgKDBgggDAgAh+QQBFAACACwAAAAABwAHAIFkZGT/AAAAAAAAAAAIGwAFCBQYIMBAggIAKFSY8KAAgwAOQpTYcKDBgAAh+QQBFAACACwAAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAgAsAQAEAAIAAwCBZGRk/wAAAAAAAAAACAcAAwAQKDAgACH5BAEUAAIALAIABAACAAMAgWRkZP8AAAAAAAAAAAgHAAMAECgwIAAh+QQBFAACACwDAAQAAgADAIFkZGT/AAAAAAAAAAAIBwADABAoMCAAIfkEARQAAwAsAAADAAYABACBAP8AZGRk/wAAAAAACA8AAQwYSJCggAAFDyYMEBAAIfkEARQAAwAsAAADAAcABACBAP8AZGRk/wAAAAAACBIABQAYQLCgQQEBDA4QoHDhgIAAIfkEARQAAwAsAQADAAYAAgCBAP8AZGRk/wAAAAAACAsABQAYQLBgQQEBAQAh+QQBFAADACwCAAMAAgABAIEA/wBkZGT/AAAAAAAIBQAFAAgIACH5BAEUAAMALAAAAwAFAAQAgQD/AGRkZP8AAAAAAAgQAAMMGCAAgMCBAw4OVDggIAAh+QQBFAADACwAAAIABgAFAIEA/wBkZGT/AAAAAAAIFAAFDBg4UECAggAMEhygkGDDgQEBACH5BAEUAAIALAEAAgAFAAUAgWRkZP8AAAAAAAAAAAgSAAMIGCggAICBAQwSVIjw4MCAADs=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 192,
       "width": 192
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "# But there's a better way!\n",
    "buffer = io.BytesIO()\n",
    "images[0].save(\n",
    "    buffer,\n",
    "    format='GIF',\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    duration=200,\n",
    "    loop=0,\n",
    ")\n",
    "buffer.seek(0)\n",
    "display(IPythonImage(data=buffer.getvalue(), width=192, height=192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac274e1f-d735-4270-951c-5484f984899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_rooms_dataloader = DataLoader(four_rooms_dataset_xf, batch_size=4, collate_fn=four_rooms_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31de7f52-3c5e-491e-8fd2-7f1cb6b4db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(four_rooms_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a81f7d80-9019-453e-a1d9-a9c7a824b349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0]['mission'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "684cebd0-585b-4c16-88da-d3e3ebc94e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset = datasets.load_dataset(\"eihli/micro-ok-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d3b37d3-2d4a-4288-b969-62c348df8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_vqa(tokenizer, sample):\n",
    "    question_cls, question = zip(*[tokenizer.encode_text(sample[\"question\"])])\n",
    "    image_cls, image = zip(*[tokenizer.encode_image(image_transform(pil_to_tensor(sample[\"image\"])))])\n",
    "    answer_cls, answer = zip(*[tokenizer.encode_text(random.choice(sample[\"answers\"])[\"answer\"])])\n",
    "    return OrderedDict({\n",
    "        'question_cls': torch.stack(question_cls),\n",
    "        'question': torch.stack(question),\n",
    "        'image_cls': torch.stack(image_cls),\n",
    "        'image': torch.stack(image),\n",
    "        'answer_cls': torch.stack(answer_cls),\n",
    "        'answer': torch.stack(answer),\n",
    "    })\n",
    "\n",
    "def vqa_collate_fn(batch):\n",
    "    padded = pad_tokens(batch)\n",
    "    masked = mask(batch)\n",
    "    return padded, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42ffeeb1-41d2-4c6c-8ba8-c4dde0e24560",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = vqa_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "142d50e7-f3fe-4fa2-8e0a-3fe133d9412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls, tokens = tokenizer.encode_image(image_transform(pil_to_tensor(sample[\"image\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0f5eb50-cbb3-43f3-87e6-f0476ef51e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([51282]),\n",
       " tensor([[-0.2378, -0.2437, -0.2390,  ...,  0.1854,  0.1832,  0.1849],\n",
       "         [-0.2446, -0.2466, -0.2453,  ...,  0.2264,  0.2325,  0.2391],\n",
       "         [-0.1818, -0.1153, -0.0956,  ...,  0.2149,  0.2101,  0.2130],\n",
       "         ...,\n",
       "         [ 0.0385,  0.0600,  0.0706,  ...,  0.2237,  0.2288,  0.2367],\n",
       "         [ 0.0707,  0.0894,  0.1001,  ...,  0.2478,  0.2362,  0.0630],\n",
       "         [-0.0377, -0.0938, -0.1630,  ...,  0.1883,  0.1839,  0.1875]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dadcaab-3798-479d-87db-521880957589",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset_xf = TransformDataset(vqa_dataset[\"train\"], partial(tokenize_vqa, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b404cd0-55f2-4b37-86b5-d1df38db535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = four_rooms_dataset_xf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "622d9989-82c1-4f9c-8dac-afeae548cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10]),\n",
       " torch.Size([1, 144, 768]),\n",
       " 'pony tail',\n",
       " 'What is the hairstyle of the blond called?')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = vqa_dataset_xf[0]\n",
    "series['question'].shape, series['image'].shape, tokenizer.decode_text(series['answer'][0].tolist()), tokenizer.decode_text(series['question'][0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0809c-5e21-46e1-8491-4f6d2f7a3fad",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba032a81-bf95-4415-aa40-17e85d449058",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18615b49-ac47-4d41-8cca-ae3d10e75291",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding = ResNetV2(layers=[3, 4, 6, 3], num_classes=EMBEDDING_DIMS)\n",
    "lookup_embedding = torch.nn.Embedding(tokenizer.n_text + tokenizer.n_discrete + tokenizer.n_modalities, EMBEDDING_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e71485-74f3-4378-b40f-d75c9cc2d6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "032419d6-c97f-495f-8f33-420ae5cb3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = four_rooms_dataset_xf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef393586-e17f-4b0c-9fd6-dcbd3b91cec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 144, 768])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tokens = sample['image']\n",
    "image_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07ee15cd-3b49-4bb7-9c37-4137fe836252",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = image_tokens.shape\n",
    "patch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "567b911c-2019-4dee-af40-4fe6e4317849",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_tokens = image_tokens.view(B*T, 3, patch_size, patch_size)\n",
    "patch_embeddings = image_embedding(patch_tokens).view(B, T, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5934c3a4-c942-4b06-a3d9-787f601c7d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_tokens = sample['mission']\n",
    "mission_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "266d2870-0a6c-427a-bc85-9a04e0c47834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_embeddings = lookup_embedding(mission_tokens)\n",
    "mission_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2c446f5-9b7a-4512-8638-7e6e30cdcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "@dataclass\n",
    "class Embedder:\n",
    "    tokenizer: Tokenizer\n",
    "    lookup_embedding: Callable\n",
    "    image_embedding: Callable\n",
    "\n",
    "    def embed(self, cls, data):\n",
    "        if self.tokenizer.is_image(cls):\n",
    "            B, T, P, C = data.shape\n",
    "            return torch.concat([self.lookup_embedding(cls.view(B*T, 1)).view(B, T, 1, -1), self.image_embedding(data.view(B*T*P, 3, 16, 16)).view(B, T, P, -1)], dim=2)\n",
    "        else:\n",
    "            B, T, C = data.shape\n",
    "            return torch.concat([self.lookup_embedding(cls.view(B*T, 1)).view(B, T, 1, -1), self.lookup_embedding(data.view(B*T, C)).view(B, T, C, -1)], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b88993f-484e-4d3d-9dc9-a9757b2ffd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, list, 8, torch.Size([1024, 1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch), type(batch[0]), len(batch[0][0]), batch[0][0]['direction'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "395495e7-197a-4ee4-962b-9ef5da192985",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m B, T, C \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdirection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      2\u001b[0m lookup_embedding(batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mview(B\u001b[38;5;241m*\u001b[39mT, C))\u001b[38;5;241m.\u001b[39mview(B, T, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "B, T, C = batch[0]['direction'].shape\n",
    "lookup_embedding(batch[0]['direction'].view(B*T, C)).view(B, T, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abeb2517-4675-4e2a-8d87-674d499f5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(tokenizer, lookup_embedding, image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c055fe-8092-43da-94f7-c5ca4ef05196",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275a252-b6c0-405f-8457-d6b884e66df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(series.values())\n",
    "for cls, data in zip(vals[::2], vals[1::2]):\n",
    "    print(cls.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25007e0c-5071-4f89-8b3f-95370e721262",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_embedding(cls).shape, lookup_embedding(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07a3a4-0a6d-4a8b-ac96-dac1d323792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c1d57-4bee-4891-a94f-d0966be7df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [embedder.embed(cls, data) for cls, data in zip(vals[::2], vals[1::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "19243da9-e6a0-4914-b557-b25ed932f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 4, 2, 8\n",
    "a = torch.arange(B*T*C*3)\n",
    "b = torch.arange(B*T*C*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ff83d23e-54d6-4469-a19d-782240c327ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [e\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43membeddings\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "[e.shape for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e1533d2d-9d8e-4b12-ab6a-10c70c23e70e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43membeddings\u001b[49m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m batch\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "batch = torch.concat([e for e in embeddings], dim=2)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0fb5edba-2ac2-4bd7-9b2d-ed22300c2651",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m B, T, S, C \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m      2\u001b[0m B\u001b[38;5;241m*\u001b[39mT\u001b[38;5;241m*\u001b[39mS\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "B, T, S, C = batch.shape\n",
    "B*T*S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c9c42e87-d363-48e9-be9c-118f173885f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 63.59M\n"
     ]
    }
   ],
   "source": [
    "transformer_config = GPTConfig(n_head=8, n_embd=512)\n",
    "gpt = GPT(transformer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7f833833-1c1d-4073-b757-d69e7fd02411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.config.n_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "338cc2a9-9d52-435d-ab6f-ca6dfc873be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 63.59M\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class MiniGatoConfig:\n",
    "    embedding_dim: int\n",
    "    sequence_length: int\n",
    "    tokenizer: Tokenizer\n",
    "    transformer_config: GPTConfig\n",
    "    transformer: GPT\n",
    "\n",
    "def init_default_config() -> MiniGatoConfig:\n",
    "    transformer_config = GPTConfig(n_head=8, n_embd=512)\n",
    "    text_encoding = tiktoken.get_encoding(\"r50k_base\")\n",
    "    tokenizer = Tokenizer(text_encoding)\n",
    "    return MiniGatoConfig(\n",
    "        embedding_dim=512,\n",
    "        sequence_length=1024,\n",
    "        tokenizer=tokenizer,\n",
    "        transformer_config=transformer_config,\n",
    "        transformer=GPT(transformer_config),\n",
    "    )\n",
    "\n",
    "default_config = init_default_config()\n",
    "\n",
    "class MiniGato(torch.nn.Module):\n",
    "    def __init__(self, config: MiniGatoConfig=default_config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.tokenizer = config.tokenizer\n",
    "        self.sequence_length = self.config.sequence_length\n",
    "        self.image_embedding = ResNetV2(layers=[3, 4, 6, 3], num_classes=EMBEDDING_DIMS)\n",
    "        self.lookup_embedding = torch.torch.nn.Embedding(self.tokenizer.n_text + self.tokenizer.n_discrete + self.tokenizer.n_modalities, EMBEDDING_DIMS)\n",
    "        self.embedder = Embedder(\n",
    "            config.tokenizer,\n",
    "            lookup_embedding,\n",
    "            image_embedding,\n",
    "        )\n",
    "        self.transformer = self.config.transformer\n",
    "        self.lm_head = torch.nn.Linear(self.transformer.config.n_embd, self.tokenizer.n_text + self.tokenizer.n_discrete + self.tokenizer.n_modalities)    \n",
    "\n",
    "    def forward(self, batch, targets=None):\n",
    "        vals = list(series.values())\n",
    "        embeddings = [embedder.embed(cls, data) for cls, data in zip(vals[::2], vals[1::2])]\n",
    "        batch = torch.concat(embeddings, dim=2)\n",
    "        B, T, S, C = batch.shape\n",
    "        out, _ = self.transformer(emb=batch.view(B*T*S, C))\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(out.last_hidden_state)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            predicted = self.lm_head(out.last_hidden_state)\n",
    "        return predicted, ys, ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0941b2fb-ec98-4bfa-97d5-74ac2dec025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_dataloader(fn):\n",
    "    it = iter(fn())\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(it)\n",
    "        except StopIteration:\n",
    "            it = iter(fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "96259b23-4246-4f20-b388-c6253553bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ab8c220a-f217-4d63-ad52-21e476b7da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = [\n",
    "    infinite_dataloader(partial(DataLoader, four_rooms_dataset_xf, batch_size=BATCH_SIZE, collate_fn=four_rooms_collate_fn)),\n",
    "    infinite_dataloader(partial(DataLoader, vqa_dataset_xf, batch_size=BATCH_SIZE, collate_fn=vqa_collate_fn)),\n",
    "]\n",
    "dl_it = cycle(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "606cff47-3993-4f10-8a7a-eb9f3255e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vqa_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78eee8cd-9ceb-4a67-b116-951b9659a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 63.59M\n"
     ]
    }
   ],
   "source": [
    "config = init_default_config()\n",
    "model = MiniGato(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "caf1c7df-662e-4e8f-92ee-b1ffb59d5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = next(dl_it)\n",
    "batch = next(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5f3cf-2f6a-421e-acab-6bff9aa8b2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90658c3c-b666-48fe-a32b-4ca509884bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_image = ResNetV2(layers=[3, 4, 6, 3], num_classes=EMBEDDING_DIMS)\n",
    "embed_text = torch.torch.nn.Embedding(tokenizer.n_text, EMBEDDING_DIMS)\n",
    "embed_discrete = torch.torch.nn.Embedding(tokenizer.n_discrete, EMBEDDING_DIMS)\n",
    "embedder = Embedder(tokenizer, lookup_embedding, image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ba99c89-16d8-4e9f-b9a3-f1bca0ca2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "228e0be2-5a1a-4490-9bd6-331ff42835a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1138be0-3e24-454b-8f8c-5628c119fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = batch[0]\n",
    "vals = list(sample.values())\n",
    "[v.shape for v in vals]\n",
    "embeddings = [embedder.embed(cls, data) for cls, data in zip(vals[::2], vals[1::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dacfa5c0-3c38-40ff-ba9c-ff97f2b9619c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 2\u001b[0m predicted, targets, attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[75], line 44\u001b[0m, in \u001b[0;36mMiniGato.forward\u001b[0;34m(self, batch, targets)\u001b[0m\n\u001b[1;32m     42\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     43\u001b[0m B, T, S, C \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 44\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(out\u001b[38;5;241m.\u001b[39mlast_hidden_state)\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/mini_gato/mini_gato/nano_gpt.py:191\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets, emb)\u001b[0m\n\u001b[1;32m    188\u001b[0m     x \u001b[38;5;241m=\u001b[39m emb\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 191\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# if we are given some desired targets also calculate the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/mini_gato/mini_gato/nano_gpt.py:104\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 104\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/neko/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/mini_gato/mini_gato/nano_gpt.py:53\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 53\u001b[0m     B, T, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;66;03m# batch size, sequence length, embedding dimensionality (n_embd)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# calculate query, key, values for all heads in batch and move head forward to be the batch dim\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     q, k, v  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_attn(x)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_embd, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "predicted, targets, attention_mask = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb5784-2f9d-4cf1-9e10-e2d2427778f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for i in tqdm(range(self.num_iterations)):\n",
    "    dl = next(dl_it)\n",
    "    batch = next(dl)\n",
    "    optimizer.zero_grad()\n",
    "    predicted, targets, attention_mask = model(batch)\n",
    "    self.losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    if self.scheduler:\n",
    "        self.scheduler.step()\n",
    "    self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ed3eb-b82c-4a67-9700-fa969a7abfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908d1f5-89f9-49cb-b282-1b1639e50e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e68cc6-f58f-4dac-acb3-cdc73cec5c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51477405-e836-4e80-8c1b-08785a3e0900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0cb578-3435-4749-ba38-e0aab2e64951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
