{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f79b73b-3072-4d25-9728-305a5a306269",
   "metadata": {},
   "source": [
    "# Mini Gato\n",
    "\n",
    "Goals:\n",
    "\n",
    "- Simplicity\n",
    "- Minimal dependencies\n",
    "- Clear explanations\n",
    "- Quickly iterable executable examples\n",
    "- Extensible architecture\n",
    "\n",
    "Non-goals:\n",
    "\n",
    "- Performance\n",
    "- Eval metrics\n",
    "\n",
    "If I succeed at the goals then I expect the path towards the non-goals will be clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ca5c8-f3e7-4305-bd11-c3e8bb8846ea",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "- ***ModalBatch*** a batch of samples of some modality\n",
    "- ***ModalSample*** an individual data sample of some modality\n",
    "- ***TextSample*** sample of text modality\n",
    "- ***VQASample*** sample of visual question answering\n",
    "- ***ActionSample*** sample of a visual (and maybe proprioception) task predicting action towards a provided textual goal\n",
    "  - The Gato paper differentiates between image/discrete tasks and image/proprioception/discrete/continuous tasks. I'm going to lump those two together. Continuous values get binned into one of 1024 discrete bins, before they get embedded. So we funnel the behavior into the same channel.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361cb630-6f78-4a7c-8903-4f7342708615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import tempfile\n",
    "import requests\n",
    "\n",
    "def acquire_shakespeare_dataset():\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    shakespeare_filepath = Path(temp_dir)/\"shakespeare.txt\"\n",
    "    if not os.path.exists(shakespeare_filepath):\n",
    "        data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "        with open(shakespeare_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(requests.get(data_url).text)\n",
    "    \n",
    "    with open(shakespeare_filepath, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # Split the dataset into each character's lines.\n",
    "    # Continue taking lines until you have at least 250 words in the sample.\n",
    "    # Add that sample to the dataset.\n",
    "    characters_lines = re.split(r\"\\n\\s*\\n\", data.strip())\n",
    "    MIN_WORDS_PER_BATCH = 250\n",
    "    sample = [characters_lines[0]]\n",
    "    num_words_in_sample = len(characters_lines[0].split())\n",
    "    text_dataset = []\n",
    "    i = 1\n",
    "    while i < len(characters_lines):\n",
    "        if num_words_in_sample > MIN_WORDS_PER_BATCH:\n",
    "            text_dataset.append(\"\\n\\n\".join(sample))\n",
    "            num_words_in_sample -= len(sample[0].split())\n",
    "            sample = sample[1:]\n",
    "        sample += [characters_lines[i]]\n",
    "        num_words_in_sample += len(characters_lines[i].split())\n",
    "        i += 1\n",
    "\n",
    "    return text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b22ade3-7a23-4fb6-8622-486231974b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = acquire_shakespeare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce958de-31cb-43c7-91c3-b0089c875437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 7184\n",
      "Character length of first 3 samples: [1632, 1688, 1891]\n",
      "\n",
      "First 80 characters of first sample:\n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in the dataset: {len(text_dataset)}\")\n",
    "print(f\"Character length of first 3 samples: {[len(x) for x in text_dataset[:3]]}\\n\")\n",
    "print(f\"First 80 characters of first sample:\\n\\n{text_dataset[0][:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3bfdf-54a3-4bb5-a6b3-12bd286d01a4",
   "metadata": {},
   "source": [
    "### Text Tokenization\n",
    "\n",
    "> Text tokens, discrete and continuous values, and actions can be directly set as targets after tokenization. [ยง 2.2](https://arxiv.org/pdf/2205.06175#page=4)\n",
    "\n",
    "I think it's going to simplify things if we combine into a single concept all of tokenization, target-setting, and masking.\n",
    "\n",
    "The idea is: we call something like `text_token_prep` or `image_token_prep` and it returns the tokens, the targets, and the attention masks. No matter the modality, we always get those three things returned.\n",
    "\n",
    "Let's write that in such a way that we get the benefit of things like autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841eee38-aca7-4419-ada8-4adcfaa0f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 1024\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4  # DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c5e350b-d84b-4020-adf4-c08b1c20a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Protocol, runtime_checkable, NewType\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class TokenData:\n",
    "    tokens: torch.Tensor = torch.tensor([], dtype=torch.float32)\n",
    "    targets: torch.Tensor = torch.tensor([], dtype=torch.int64)\n",
    "    attention_mask: torch.Tensor = torch.tensor([], dtype=torch.uint8)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.tokens = self.tokens.to(device)\n",
    "        self.targets = self.targets.to(device)\n",
    "        self.attention_mask = self.attention_mask.to(device)\n",
    "        return self\n",
    "\n",
    "class TextTokenData(TokenData):\n",
    "    pass\n",
    "\n",
    "class ImageTokenData(TokenData):\n",
    "    pass\n",
    "# etc... I don't know exactly what all types we'll need for this.\n",
    "# \n",
    "# Example: will we need a single VisualQuestionAnsweringTokenData?\n",
    "# Or, will that be a concatenation of TextTokenData and ImageTokenData?\n",
    "# I just don't know yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27da9006-5c3b-4f94-bf32-0d90baec64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenator(ABC):\n",
    "    @abstractmethod\n",
    "    def __call__(self) -> TokenData:\n",
    "        pass\n",
    "\n",
    "class TextTokenator(Tokenator):\n",
    "    def __init__(self, tokenizer):   \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __call__(self, batch, **kwargs) -> TokenData:\n",
    "        tokenized =  self.tokenizer(batch, **kwargs)\n",
    "        xs = tokenized[\"input_ids\"][:, :-1]\n",
    "        ms = tokenized[\"attention_mask\"][:, :-1]\n",
    "        ys = tokenized[\"input_ids\"][:, 1:]\n",
    "        return TextTokenData(tokens=xs, targets=ys, attention_mask=ms)\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.tokenizer.func.decode(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.tokenizer.func.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7951172-6c5d-40a6-aaa0-eaf9ab41a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eed3fd06-8b45-4f85-bcb0-458f28c8f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixing with _ to signify global.\n",
    "__text_tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\", clean_up_tokenization_spaces=True)\n",
    "__text_tokenizer.pad_token = __text_tokenizer.eos_token\n",
    "_text_tokenizer = partial(\n",
    "    __text_tokenizer,\n",
    "    max_length=SEQUENCE_LENGTH+1,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "28a3a60a-f4b7-43f6-8d2c-b34722d99d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenator = TextTokenator(_text_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d44f51ee-1139-4d8e-9d6a-c8efd11d71fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextTokenData(tokens=tensor([[15496,    11,   995,  ..., 50256, 50256, 50256]]), targets=tensor([[   11,   995,     0,  ..., 50256, 50256, 50256]]), attention_mask=tensor([[1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenator([\"Hello, world!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0bb363b2-a3aa-4157-a99f-669b3bbaa40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6381a53a-e020-41de-a2ca-bb510017e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataloader = DataLoader(text_dataset, batch_size=BATCH_SIZE, collate_fn=text_tokenator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e1e85b77-12ed-4deb-a67d-3d5b12a7e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = next(iter(text_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "430c3ce4-348a-4319-948d-ad8041241154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1024]), torch.Size([4, 1024]), torch.Size([4, 1024]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens.tokens.shape, text_tokens.targets.shape, text_tokens.attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b56ec-ab72-49c3-bbcd-6dbbbdb6ad57",
   "metadata": {},
   "source": [
    "Make sure the 4th element of our target matches what we expect to be predicted after the 4th element of our input. We're tokenizing and offsetting correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe0b1513-460a-4074-9327-e5aa5cfae8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proce'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "69b9b68a-5f6e-4abe-b39c-570458d5a7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5962, 22307,    25,   198,  8421]),\n",
       " tensor([22307,    25,   198,  8421]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens.tokens[0, :5], text_tokens.targets[0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "40af3be3-1429-4670-87f5-39b72a69869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First Citizen:\\nBefore', ' we')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenator.decode(text_tokens.tokens[0, :5]), text_tokenator.decode(text_tokens.targets[0, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2953e0-2609-41c8-b535-025985884673",
   "metadata": {},
   "source": [
    "### Does it work with multiple workers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e4677de-0485-4d98-ae8e-f5aa9e84b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataloader = DataLoader(text_dataset, batch_size=BATCH_SIZE, collate_fn=text_tokenator, num_workers=4)\n",
    "dl = iter(text_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98a85366-db89-420e-b574-1fe148f19abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f678153-78ea-4169-820a-2e01712fa373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b47527658647759b0c2e0495360f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    next(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50659529-21fc-4abf-8c4e-38fcbe0446c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea11b10f01436cb2c7c663694b3407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    next(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11b6d92d-3fd8-4457-80fe-b7c940399146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import GPT2TokenizerFast, GPT2Config, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90ccdf82-72b7-495b-9c2f-f5bdcb576170",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "PATCH_SIZE = 16\n",
    "class MiniGato(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        transformer=None,\n",
    "        text_tokenator=None,\n",
    "        sequence_length=SEQUENCE_LENGTH,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        patch_size=PATCH_SIZE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert text_tokenator, \"text_tokenizer is a required arg\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.text_tokenator = text_tokenator\n",
    "        self.text_embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embedding_dim,\n",
    "        )\n",
    "\n",
    "        self.transformer = transformer\n",
    "        self.lm_head = nn.Linear(self.transformer.config.hidden_size, self.text_tokenator.vocab_size)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.text_tokenator.vocab_size\n",
    "\n",
    "    def embed_text(self, tokens):\n",
    "        return self.text_embedding(tokens)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        text_tokens = next((t for t in tokens if isinstance(t, TextTokenData)), [])\n",
    "        text_embeddings = self.text_embedding(text_tokens.tokens)\n",
    "        transformed = self.transformer(inputs_embeds=text_embeddings)\n",
    "        out = self.lm_head(transformed.last_hidden_state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6be93b47-fd0f-46f6-9599-4b0361084a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = GPT2Config(\n",
    "    n_embd=EMBEDDING_DIM\n",
    ")\n",
    "transformer = GPT2Model(configuration)\n",
    "model = MiniGato(transformer=transformer, text_tokenator=text_tokenator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1dea7a9a-3a45-424c-9cb9-7c3d2fa01550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = _text_tokenizer([\"hello, world\", \"foobar\"], return_tensors=\"pt\", padding=\"max_length\", max_length=8)\n",
    "model.text_embedding(tokens[\"input_ids\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b619a27-706a-4067-bdac-3256dcf9b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "30e70122-81a5-4fb0-8119-800d61a8cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model([next(dl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce4b4ef8-70dd-4ad6-893b-942fe0e75291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([4, 1024, 50257]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out), out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a324f-41ef-49f2-8013-fd692de0479f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b8b940cb-83ac-421a-8682-432f774167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss\n",
    "##\n",
    "## See section 2.3 of the Gato paper.\n",
    "##\n",
    "##   Let b index a training batch of sequences B. We define a masking function m\n",
    "##   such that m(b, l) = 1 if the token at index l is either from text or from\n",
    "##   the logged action of an agent, and 0 otherwise. The training loss for a\n",
    "##   batch B can then be written as...\n",
    "def cross_entropy(predicted, target, mask):\n",
    "    # See: https://youtu.be/kCc8FmEb1nY?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=1553\n",
    "    B, T, C = predicted.shape\n",
    "    predicted = predicted.view(B * T, C)\n",
    "    target = target.view(-1)\n",
    "    losses = F.cross_entropy(predicted, target, reduction=\"none\")\n",
    "    losses = losses * mask.squeeze(-1).view(-1)\n",
    "    loss = losses.sum() / mask.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ad975cb2-68e0-474f-a480-00ed49cc2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c701a514-06cd-4929-82fd-38c8148c37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    configuration = GPT2Config(\n",
    "        n_embd=EMBEDDING_DIM\n",
    "    )\n",
    "    transformer = GPT2Model(configuration)\n",
    "    model = MiniGato(transformer=transformer, text_tokenator=text_tokenator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6e874b0-f171-44b0-852c-2244ae40f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b15135cf-0098-4c99-8c16-872f31f01f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniGato(\n",
       "  (text_embedding): Embedding(50257, 768)\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "abf30c0f-4759-44b3-b9da-f9ccecc5caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2.02e+08\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "75f877d8-e046-49bd-8923-b4cdabe3879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optimizer(params):\n",
    "    optimizer = torch.optim.AdamW(params)\n",
    "    return optimizer\n",
    "\n",
    "optimizer = init_optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4356174a-3f1c-462b-bb85-8d1b65e374da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6c8c464a-abf1-4edb-8f08-e05ed6bd936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fresh_text_dataloader():\n",
    "    return DataLoader(text_dataset, batch_size=BATCH_SIZE, collate_fn=text_tokenator, num_workers=4)\n",
    "text_dataloader_iter = iter(fresh_text_dataloader())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "902fcb9d-37d1-45d5-9359-cf6e54b04443",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token_data = next(text_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4d962e64-291b-46f2-b66c-6db7dee1298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7d130391-fae0-44d5-af20-4e0f8d348986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2890"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9af19-39b2-4d6b-a468-9cad36a37be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b87ab776-db73-41ed-836a-380cb035ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step by step.\n",
    "model.train()\n",
    "text_dataloader_iter = iter(fresh_text_dataloader())\n",
    "text_token_data = next(text_dataloader_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff6a91-885f-4237-be69-6762c3bb954c",
   "metadata": {},
   "source": [
    "### Does it work? Can we overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "21af8d33-bf6c-4aa2-bbc7-ddeec3d0e01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5962, 22307,    25,  ..., 50256, 50256, 50256],\n",
       "        [ 3237,    25,   198,  ..., 50256, 50256, 50256],\n",
       "        [ 5962, 22307,    25,  ..., 50256, 50256, 50256],\n",
       "        [ 3237,    25,   198,  ..., 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token_data.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bc07a60b-51d3-4a55-84f6-9737408b12d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\nSecond Citizen:\\nWould you proceed especially against Caius Marcius?\\n\\nAll:\\nAgainst him first: he's a very dog to the commonalty.\\n\\nSecond Citizen:\\nConsider you what services he has done for his country?\\n\\nFirst Citizen:\\nVery well; and could be content to give him good\\nreport fort, but that he pays himself with being proud.\\n\\nSecond Citizen:\\nNay, but speak not maliciously.\\n\\nFirst Citizen:\\nI say unto you, what he hath done famously, he did\\nit to that end: though soft-conscienced men can be\\ncontent to say it was for his country he did it to\\nplease his mother and to be partly proud; which he\\nis, even till the altitude of his virtue.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.text_tokenator.decode(text_token_data.tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e1468b7c-6898-4009-9d8e-635f148809f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniGato(\n",
       "  (text_embedding): Embedding(50257, 768)\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e9956bdf-6f8d-496d-bd6e-a27bf5dcb288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7071fd75d6094b11add8f7e950744bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    text_token_data.tokens = text_token_data.tokens.to(device)\n",
    "    text_token_data.targets = text_token_data.targets.to(device)\n",
    "    text_token_data.attention_mask = text_token_data.attention_mask.to(device)\n",
    "    \n",
    "    x = [text_token_data]  # Model branches of type to embed, so we can't send just `.tokens`.\n",
    "    y = torch.concat([text_token_data.targets])\n",
    "    m = torch.concat([text_token_data.attention_mask])\n",
    "    optimizer.zero_grad()\n",
    "    # forward\n",
    "    text_tokens = next((t for t in x if isinstance(t, TextTokenData)), [])\n",
    "    text_embeddings = model.text_embedding(text_tokens.tokens)\n",
    "    transformed = model.transformer(inputs_embeds=text_embeddings)  # Would be stacked with other modalities.\n",
    "    p = model.lm_head(transformed.last_hidden_state)\n",
    "    # The above is effectively `p = model(x)`\n",
    "    \n",
    "    loss = cross_entropy(p, y, m)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "910e75ad-e444-46c0-b2d8-7386e913de51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextTokenData(tokens=tensor([[ 5962, 22307,    25,  ..., 50256, 50256, 50256]], device='cuda:0'), targets=tensor([[22307,    25,   628,  ..., 50256, 50256, 50256]], device='cuda:0'), attention_mask=tensor([[1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.text_tokenator([text]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8d1474fd-572a-4d19-be15-b23b53a2e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      " to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "text = \"First Citizen:\"\n",
    "token = None\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    while i < 20 and token != model.text_tokenator.tokenizer.func.eos_token_id:\n",
    "        token_data = model.text_tokenator([text]).to(device)\n",
    "        length = token_data.attention_mask.sum().item()\n",
    "        p = model([token_data])\n",
    "        # chosen = torch.multinomial(p.softmax(dim=2)[:, length-1], num_samples=1)\n",
    "        # with temperature\n",
    "        heat = 0.1\n",
    "        heated = p / heat\n",
    "        chosen = torch.multinomial(heated.softmax(dim=2)[:, length-1], num_samples=1)\n",
    "        token = chosen[0]\n",
    "        text += model.text_tokenator.decode(chosen[0])\n",
    "        i += 1\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "faba9643-9ae7-4513-9383-43ce88cf68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    i = 100\n",
    "    text_i = 0\n",
    "    model.train()\n",
    "    text_dataloader_iter = iter(fresh_text_dataloader())\n",
    "    for epoch in tqdm(range(i)):\n",
    "        try:\n",
    "            text_token_data = next(text_dataloader_iter)\n",
    "        except StopIteration:\n",
    "            text_i += 1\n",
    "            text_dataloader_iter = iter(fresh_text_dataloader())\n",
    "            text_token_data = next(text_dataloader_iter)\n",
    "        text_token_data.tokens = text_token_data.tokens.to(device)\n",
    "        text_token_data.targets = text_token_data.targets.to(device)\n",
    "        text_token_data.attention_mask = text_token_data.attention_mask.to(device)\n",
    "        # Eventually we'll have other modalities' dataloaders and we'll concat their results below.\n",
    "        x = [text_token_data]  # Model branches of type to embed.\n",
    "        y = torch.concat([text_token_data.targets])\n",
    "        m = torch.concat([text_token_data.attention_mask])\n",
    "        optimizer.zero_grad()\n",
    "        p = model(x)\n",
    "        loss = cross_entropy(p, y, m)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{i}], Loss: {loss.item()}\")\n",
    "    print(f\"Epoch [{epoch}/{i}], Loss: {loss.item()}\")\n",
    "    print(f\"text: {text_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac63f2e-3cde-4f10-9b0b-8291e3185838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "c3c33726-82b1-46df-9711-749c927db409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c5d7232d90430091db24f944d9eaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Loss: 5.402276515960693\n",
      "Epoch [10/100], Loss: 5.388052463531494\n",
      "Epoch [20/100], Loss: 6.653019905090332\n",
      "Epoch [30/100], Loss: 5.597199440002441\n",
      "Epoch [40/100], Loss: 6.08368444442749\n",
      "Epoch [50/100], Loss: 5.975568771362305\n",
      "Epoch [60/100], Loss: 5.656105995178223\n",
      "Epoch [70/100], Loss: 5.5299530029296875\n",
      "Epoch [80/100], Loss: 5.9142537117004395\n",
      "Epoch [90/100], Loss: 5.648364067077637\n",
      "Epoch [99/100], Loss: 5.458223819732666\n",
      "text: 0\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57f37e-635c-4e7b-93f4-2a436cea47c9",
   "metadata": {},
   "source": [
    "# VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9cff1ead-57ce-494a-8aca-5e64729016ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datasets\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5b2d8edb-1c77-4ae3-ba8b-5709963143dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dataset = datasets.load_dataset(\"eihli/micro-ok-vqa\").with_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "62e5fe49-26a6-4a10-9d80-69006dc9ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'question_type', 'confidence', 'answers', 'image_id', 'answer_type', 'question_id', 'question'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'question_type', 'confidence', 'answers', 'image_id', 'answer_type', 'question_id', 'question'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0ff45fd5-fe18-4851-9449-04cb25f98118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question_type', 'confidence', 'answers', 'image_id', 'answer_type', 'question_id', 'question'],\n",
       "    num_rows: 80\n",
       "})"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b2ab60a1-095f-4e1c-9192-15a2081e2492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 479, 640])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_dataset['train']['image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5acafcdb-e26f-4e4a-ad83-d5461f4651ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the hairstyle of the blond called?',\n",
       " 'How old do you have to be in canada to do this?',\n",
       " 'Can you guess the place where the man is playing?',\n",
       " 'Which rail company is named after a town in new mexico?',\n",
       " 'Is the boy swimming or doing another water activity?']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_dataset[\"train\"][\"question\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8a630670-8fe1-4de8-8c84-7125c42b315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " [{'answer': 'pony tail',\n",
       "   'raw_answer': 'pony tail',\n",
       "   'answer_confidence': 'yes',\n",
       "   'answer_id': tensor(1)},\n",
       "  {'answer': 'pony tail',\n",
       "   'raw_answer': 'pony tail',\n",
       "   'answer_confidence': 'yes',\n",
       "   'answer_id': tensor(2)},\n",
       "  {'answer': 'pony tail',\n",
       "   'raw_answer': 'pony tail',\n",
       "   'answer_confidence': 'yes',\n",
       "   'answer_id': tensor(3)}])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vqa_dataset[\"train\"][\"answers\"][0]), vqa_dataset[\"train\"][\"answers\"][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6b42f359-954e-4059-ac69-9b8732831253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First things first, let's get the images resized, cropped, and normalized.\n",
    "\n",
    "vqa_transform = transforms.Compose([\n",
    "    # No particular reason to use `transforms.Compose` here since we're only doing one transform. But it's nice to know about.\n",
    "    transforms.RandomResizedCrop((192, 192), (0.5, 1.0)),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e9f94f65-9f36-495e-979f-0d1b751a3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "382730b1-eccb-4d1c-bfe1-68c79884a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        answer = random.choice(item[\"answers\"])[\"answer\"]\n",
    "        question = item[\"question\"]\n",
    "        image = self.transform(item[\"image\"])        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"image\": image,\n",
    "            \"answer\": answer,\n",
    "        }        \n",
    "\n",
    "transformed_vqa_dataset = TransformDataset(vqa_dataset[\"train\"], vqa_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b8143d0c-c829-4197-9ce4-625edb4da856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_ok_vqa_collate_fn(batch):\n",
    "    answers = [random.choice(el[\"answers\"])[\"answer\"] for el in batch]\n",
    "    questions = [el[\"question\"] for el in batch]\n",
    "    images = torch.stack([micro_ok_vqa_transform(el[\"image\"]) for el in batch])\n",
    "    return {\n",
    "        \"question\": questions,\n",
    "        \"image\": images,\n",
    "        \"answer\": answers,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "37e952dd-c7af-45ff-81bb-0d77975964cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0494, -2.0494, -2.0323,  ..., -1.3473, -1.2788, -1.3130],\n",
       "         [-2.0494, -2.0323, -2.0837,  ..., -1.0219, -1.0219, -1.0904],\n",
       "         [-2.0665, -2.0494, -2.0837,  ..., -1.0390, -1.0904, -1.0390],\n",
       "         ...,\n",
       "         [ 0.7077,  0.6049,  0.5193,  ...,  0.9132,  0.8618,  0.6906],\n",
       "         [ 0.6906,  0.5364,  0.4679,  ...,  1.2385,  1.1187,  1.0331],\n",
       "         [ 0.7248,  0.5536,  0.5022,  ...,  1.4612,  1.4440,  1.4783]],\n",
       "\n",
       "        [[-0.8452, -0.8452, -0.8452,  ..., -0.1800, -0.1625, -0.1800],\n",
       "         [-0.8803, -0.8627, -0.8803,  ..., -0.1625, -0.1450, -0.1450],\n",
       "         [-0.9153, -0.8803, -0.8978,  ..., -0.2850, -0.3025, -0.2675],\n",
       "         ...,\n",
       "         [ 0.5028,  0.3627,  0.2052,  ...,  0.3978,  0.3978,  0.2927],\n",
       "         [ 0.5028,  0.3277,  0.1702,  ...,  1.1681,  1.0280,  0.9580],\n",
       "         [ 0.5203,  0.3277,  0.2052,  ...,  1.6758,  1.6583,  1.6933]],\n",
       "\n",
       "        [[ 0.1128,  0.1128,  0.1302,  ...,  0.4265,  0.4265,  0.4265],\n",
       "         [ 0.1128,  0.1128,  0.0779,  ...,  0.5311,  0.5485,  0.5311],\n",
       "         [ 0.0779,  0.0953,  0.0779,  ...,  0.5311,  0.5136,  0.5659],\n",
       "         ...,\n",
       "         [ 0.6008,  0.4788,  0.3568,  ...,  0.3393,  0.2871,  0.1825],\n",
       "         [ 0.6182,  0.4614,  0.3045,  ...,  1.5768,  1.4025,  1.2631],\n",
       "         [ 0.6531,  0.4788,  0.3219,  ...,  2.1171,  2.1171,  2.0997]]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vqa_dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6d81fabb-4c17-4d9d-a068-b02f9f1736c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Load pre-trained ResNet18\n",
    "resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1826632b-04fa-42a8-896c-46e1c9c88ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTokenator(Tokenator):\n",
    "    def __init__(self, tokenizer):   \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __call__(self, batch, **kwargs) -> TokenData:\n",
    "        tokenized =  self.tokenizer(batch, **kwargs)\n",
    "        xs = tokenized[\"input_ids\"][:, :-1]\n",
    "        # We're not predicting image tokens, so zero out the attention and predictions.\n",
    "        ms = ys = torch.zeros(xs.shape[:2])\n",
    "        return ImageTokenData(tokens=xs, targets=ys, attention_mask=ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "242c21ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7131d1fe-ff58-4a76-a1f2-78ceb486dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_dl = DataLoader(vqa_dataset[\"train\"], batch_size=BATCH_SIZE, collate_fn=micro_ok_vqa_collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8721d35-e5ac-4220-870e-45ed3b201e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = iter(vqa_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "501819e9-29da-48e2-90f7-c2d3ff6d834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_batch = next(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57bd4154-69f2-4b47-8cae-df212f54b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 192, 192])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_batch[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8c07945-992b-4f25-93f9-30b828f08efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "232e02ae-c43e-4e1c-9b9a-f77e3950427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc8e6373-342d-4810-b574-fdf9eac3bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = vqa_batch[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "500a5ec8-690e-4f7e-9bd3-f71e5691bcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 432])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = rearrange(images, 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=PATCH_SIZE, s2=PATCH_SIZE)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6c1bd0b-86e4-46ad-a9ac-0c4a48bac5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 432])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_matplotlib_dims = rearrange(images, 'b c (h s1) (w s2) -> b (h w) s1 s2 c', s1=PATCH_SIZE, s2=PATCH_SIZE)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a83cb8d-cff1-475d-b741-3d5c7f2cd8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x100 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=16, figsize=(8, 1))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(16):\n",
    "        axes[i, j].imshow(patches_matplotlib_dims[0][i * 16 + j])\n",
    "        axes[i, j].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4821112e-a8cb-4032-a6f4-04eeda48ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 192, 192])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed = rearrange(patches, 'b (ph pw) (sh sw c) -> b c (ph sh) (pw sw)', ph=16, pw=16, sh=PATCH_SIZE, sw=PATCH_SIZE)\n",
    "reconstructed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "581b684c-12b1-44c5-93b7-2ebc0a581292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reconstructed == images).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c39af499-1c2a-490e-9a38-cae851fb6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_patches(images, patch_size=12):\n",
    "    return rearrange(images, 'b c (h s1) (w s2) -> b (h w) (c s1 s2)', s1=patch_size, s2=patch_size)\n",
    "\n",
    "# We don't need this as part of Gato. It's just here to play with and visually test the code.\n",
    "def patches_to_image(patches, image_shape, patch_size=12):\n",
    "    channels, height, width = image_shape\n",
    "    patch_height = height // patch_size\n",
    "    patch_width = width // patch_size\n",
    "    reconstructed = rearrange(\n",
    "        patches, \n",
    "        'b (ph pw) (c ps1 ps2) -> b c (ph ps1) (pw ps2)',\n",
    "        ph=patch_height,\n",
    "        pw=patch_width,\n",
    "        ps1=patch_size,\n",
    "        ps2=patch_size,\n",
    "    )\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "181ac218-0a5e-4607-87f8-f7ce313b3761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And to prove that we can go from image -> patch -> image\n",
    "recovered_images = patches_to_image(images_to_patches(images), (3, 192, 192))\n",
    "(recovered_images == images).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b95a8fe0-ee5e-452a-9d41-f61e08193d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_between_minus_one_plus_one(t: torch.Tensor):\n",
    "    min_val, max_val = t.min(), t.max()\n",
    "    if min_val == max_val:\n",
    "        return torch.zeros_like(t)\n",
    "    normalized = 2 * (t - min_val) / (max_val - min_val) - 1\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1902b9e-03a1-4b55-a3e6-bb8156d43d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -0.6000, -0.2000,  0.2000,  0.6000,  1.0000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_to_between_minus_one_plus_one(torch.arange(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7518563f-c284-475e-aa50-b170b04ef053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a small deviation in the NEKO codebase from the paper.\n",
    "# The paper normalizes _per patch_. The NEKO codebase currently normalizes _per image_.\n",
    "# https://github.com/eihli/NEKO/blob/master/gato/policy/embeddings.py#L38\n",
    "# This notebook normalizeds per patch. That's what this utility helps.\n",
    "def apply_along_dimension(func, dim, tensor):\n",
    "    tensor = tensor.transpose(0, dim)\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.reshape(shape[0], -1)\n",
    "    result = torch.stack([func(tensor[:, i]) for i in range(tensor.size(1))], dim=1)\n",
    "    result = result.reshape(shape).transpose(0, dim)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34010d4d-869b-4ebf-882b-2802d42990a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting tensor:\n",
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3]],\n",
      "\n",
      "        [[ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11]]])\n",
      "\n",
      "t * t.min() along dim 0:\n",
      "tensor([[[ 0,  1],\n",
      "         [ 4,  9]],\n",
      "\n",
      "        [[ 0,  5],\n",
      "         [12, 21]],\n",
      "\n",
      "        [[ 0,  9],\n",
      "         [20, 33]]])\n",
      "\n",
      "t * t.min() along dim 1:\n",
      "tensor([[[ 0,  1],\n",
      "         [ 0,  3]],\n",
      "\n",
      "        [[16, 25],\n",
      "         [24, 35]],\n",
      "\n",
      "        [[64, 81],\n",
      "         [80, 99]]])\n",
      "\n",
      "t * t.min() along dim 2:\n",
      "tensor([[[  0,   0],\n",
      "         [  4,   6]],\n",
      "\n",
      "        [[ 16,  20],\n",
      "         [ 36,  42]],\n",
      "\n",
      "        [[ 64,  72],\n",
      "         [100, 110]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = torch.arange(12).view(3, 2, 2)\n",
    "print(f\"starting tensor:\\n{example}\\n\")\n",
    "print(f\"t * t.min() along dim 0:\\n{apply_along_dimension(lambda t: t * t.min(), 0, example)}\\n\")\n",
    "print(f\"t * t.min() along dim 1:\\n{apply_along_dimension(lambda t: t * t.min(), 1, example)}\\n\")\n",
    "print(f\"t * t.min() along dim 2:\\n{apply_along_dimension(lambda t: t * t.min(), 2, example)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d445099-0188-41c3-b3bc-23d177d9da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokensImage = namedtuple(\"TokensImage\", [\"xs\", \"ys\", \"ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62a7506e-02c0-42f7-a374-1f9ef108d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_image(image: torch.Tensor, patch_size=PATCH_SIZE) -> torch.Tensor:\n",
    "    \"\"\"Convert images to patches, normalize each patch, then prepare it for\n",
    "    embedding by reshaping to CxHxW so that we can send it through the conv\n",
    "    layers of a ResNet block.\n",
    "    \"\"\" \n",
    "    image = images_to_patches(image, patch_size=patch_size)\n",
    "    # Hardcoding as a reminder to do something smarter\n",
    "    SQUARE_ROOT_OF_PATCH_SIZE = 3.464\n",
    "    xs = (\n",
    "        apply_along_dimension(\n",
    "            normalize_to_between_minus_one_plus_one, 2, image\n",
    "        )\n",
    "        / SQUARE_ROOT_OF_PATCH_SIZE\n",
    "    )\n",
    "    # We don't predict images, but we need ys\n",
    "    # becaues these image ys will be in our \n",
    "    # concatenated ys of text/image/action/etc...\n",
    "    ys = torch.zeros((xs.size(0), xs.size(1)))\n",
    "    ms = torch.zeros_like(ys)  # Same story as above.\n",
    "    return TokensImage(xs, ys, ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f09c059a-9c71-4630-b2f7-f0f6cf993a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tokens = tokenize_image(vqa_batch[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbe8aaf9-63aa-40c4-953a-2423f08a1d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 256, 432]), torch.Size([4, 256]), torch.Size([4, 256]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tokens.xs.shape, image_tokens.ys.shape, image_tokens.ms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a736b3-3407-4044-97cf-d460f7138f87",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4116062-78ae-48e9-a035-26afea3ca804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minari\n",
    "\n",
    "minigrid_dataset = minari.load_dataset('D4RL/minigrid/fourrooms-v0', download=True)\n",
    "env  = minigrid_dataset.recover_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15213a19-9fbf-4abb-a193-c0e9b1aebd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': Text(1, 14, charset=                                                              ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''(),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdeeeffghijklmnnoopqrrssttuvwxyzz{}))\n",
      "Action space: Discrete(7)\n",
      "Total episodes: 590\n",
      "Total steps: 10010\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space:\", minigrid_dataset.observation_space)\n",
    "print(\"Action space:\", minigrid_dataset.action_space)\n",
    "print(\"Total episodes:\", minigrid_dataset.total_episodes)\n",
    "print(\"Total steps:\", minigrid_dataset.total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e92b937f-a4ac-4315-beb0-27c67fcf63de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE ID'S SAMPLE 0: [31, 348, 9, 536, 400]\n",
      "EPISODE ID'S SAMPLE 1: [103, 265, 544, 204, 477]\n",
      "EPISODE ID'S SAMPLE 2: [302, 158, 14, 505, 522]\n",
      "EPISODE ID'S SAMPLE 3: [240, 125, 371, 87, 435]\n",
      "EPISODE ID'S SAMPLE 4: [468, 125, 305, 489, 469]\n"
     ]
    }
   ],
   "source": [
    "minigrid_dataset.set_seed(seed=123)\n",
    "\n",
    "for i in range(5):\n",
    "    # sample 5 episodes from the dataset\n",
    "    episodes = minigrid_dataset.sample_episodes(n_episodes=5)\n",
    "    # get id's from the sampled episodes\n",
    "    ids = list(map(lambda ep: ep.id, episodes))\n",
    "    print(f\"EPISODE ID'S SAMPLE {i}: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9be5ef71-357d-4220-b9f0-bca382f6db64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 7, 7, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes[0].observations[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b74b036-8798-4bee-acd9-b549b7052f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes[0].observations[\"direction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fdd70c4-09b5-445f-b5bb-391df3b584fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6655d914-f99b-4689-be44-54baa430a1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 0, 2, 2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dd4020d-7d6c-47cf-a01f-5c0e05334d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minigrid.core import constants as mgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "899e5a17-61ca-4d29-b2e7-97fd155eee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minigrid_to_rgb(obs):\n",
    "    _obs = torch.zeros(obs.shape, dtype=torch.uint8)\n",
    "    for i in range(_obs.size(0)):\n",
    "        for j in range(_obs.size(1)):\n",
    "            _obs[i, j] = torch.from_numpy(mgc.COLORS[mgc.IDX_TO_COLOR[obs[i, j, 1]]]).to(torch.uint8)\n",
    "    return _obs.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "229940fc-d576-43cd-a24c-4c64eea02320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 3)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = episode.observations[\"image\"][0]\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f7ad6c46-0e31-4d23-93e8-478e28cbd4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgc.IDX_TO_COLOR\n",
    "obs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fcfe225d-ccec-4e01-948d-30818dd309f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255, 255, 255, 255, 100,   0, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255],\n",
       "         [255, 255, 255, 255, 100, 255, 255]],\n",
       "\n",
       "        [[  0,   0,   0,   0, 100, 255,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0],\n",
       "         [  0,   0,   0,   0, 100,   0,   0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minigrid_to_rgb(episode.observations[\"image\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d243861d-a311-4120-aef5-e7294928136d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = episode.observations[\"image\"].shape[0]\n",
    "fig, axs = plt.subplots(l, 1, figsize=(15, 15))\n",
    "for i in range(l):\n",
    "    axs[i].imshow(minigrid_to_rgb(episode.observations[\"image\"][i]).permute(1, 2, 0))\n",
    "    axs[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33592b-a844-48b4-96b9-b5c26da316b0",
   "metadata": {},
   "source": [
    "We might want to use something smaller than 192x192. That was a reasonable size for photographs. But this is upscaled from a 7x7 grid. We don't need that much resolution. And the smaller the image, the more we can fit into a context window, which is good for episodic tasks like robotics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f107d030-2b5c-4e80-b6b7-49f56ca2351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_PATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "72051048-3c03-4639-b062-81573b791c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "minigrid_image_resize = transforms.Resize(\n",
    "    (CONTROL_PATCH_SIZE * 6, CONTROL_PATCH_SIZE * 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "27465f47-85b1-4505-99b0-0f3e0b8f9ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 7])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minigrid_to_rgb(episode.observations[\"image\"][5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8fa2f1d9-fa49-43e6-8b1e-88f4949872a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 24])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_minari_grid_observation_image = minigrid_image_resize([minigrid_to_rgb(episode.observations[\"image\"][1])])\n",
    "resized_minari_grid_observation_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "623ab239-eec7-42ee-853d-bf9c8ce37153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7c1d1f6660c0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(minigrid_image_resize([minigrid_to_rgb(episode.observations[\"image\"][8])])[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "975df50b-52fd-4d06-9f38-4d56c5bc9418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpisodeData(id=468, total_steps=10, observations={direction: ndarray of shape (11,) and dtype int64, image: ndarray of shape (11, 7, 7, 3) and dtype uint8, mission: ['reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal', 'reach the goal']}, actions=ndarray of shape (10,) and dtype int64, rewards=ndarray of 10 floats, terminations=ndarray of 10 bools, truncations=ndarray of 10 bools, infos=dict with the following keys: [])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "98e50480-f8c9-41a3-ab84-ee9c0d2e859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokensObservation = namedtuple(\"TokensObservation\", [\"xs\", \"ys\", \"ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cedd634f-ea6b-462b-aa3a-00468ddf1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_observation(vocab_size, batch):\n",
    "    xs = torch.tensor(batch, dtype=torch.int)\n",
    "    xs = xs + vocab_size\n",
    "    ys = torch.zeros_like(xs)  # non-textual observations aren't predicted\n",
    "    ms = torch.zeros_like(ys)  # ^ ...\n",
    "    return TokensObservation(xs, ys, ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3ef46757-309e-47af-8ac6-772e0aa4b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokensAction = namedtuple(\"TokensAction\", [\"xs\", \"ys\", \"ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "009e4c91-2723-4864-8c10-62b74fa06988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_action(vocab_size, batch):\n",
    "    xs = torch.tensor(batch, dtype=torch.int)\n",
    "    xs = xs + vocab_size\n",
    "    ys = torch.zeros_like(xs)  # non-textual observations aren't predicted\n",
    "    ms = torch.zeros_like(ys)  # ^ ...\n",
    "    return TokensAction(xs, ys, ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "68e8e7bb-868a-4601-b79c-6c9c85b96ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91]\n"
     ]
    }
   ],
   "source": [
    "separator_token = _text_tokenizer(\"|\")[\"input_ids\"]\n",
    "print(separator_token)\n",
    "SEPARATOR_TOKEN = torch.tensor([91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "59427f14-045d-47ee-a3a3-be090ea87937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Timestep = namedtuple(\"Timestep\", [\"text\", \"image\", \"discrete\", \"separator\", \"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7f295-059b-4995-93b4-74c4ac15b386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "de963649-410b-43c3-ad24-77d9f6e1d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minigrid_collate_fn(tokenize_text, tokenize_image, tokenize_discrete, vocab_size, batch):\n",
    "    sequenced = []\n",
    "    for sample in batch:\n",
    "        text_tokens = tokenize_text(\n",
    "            sample.observations[\"mission\"]\n",
    "        )\n",
    "        image_tokens = tokenize_image([\n",
    "            minigrid_image_resize(minigrid_to_rgb(image))\n",
    "            for image in sample.observations[\"image\"]\n",
    "        ])\n",
    "        discrete_tokens = tokenize_observation(\n",
    "            vocab_size,\n",
    "            [[d] for d in sample.observations[\"direction\"]],\n",
    "        )\n",
    "        action_tokens = tokenize_action(\n",
    "            vocab_size,\n",
    "            [[a] for a in sample.actions]\n",
    "        )\n",
    "        timesteps = []\n",
    "        for i in range(len(sample.actions)):\n",
    "            xs = Timestep(\n",
    "                text_tokens.xs[i],\n",
    "                image_tokens.xs[i],\n",
    "                discrete_tokens.xs[i],\n",
    "                SEPARATOR_TOKEN,\n",
    "                action_tokens.xs[i],\n",
    "            )\n",
    "            ys = Timestep(\n",
    "                text_tokens.ys[i],\n",
    "                image_tokens.ys[i],\n",
    "                discrete_tokens.ys[i],\n",
    "                SEPARATOR_TOKEN,\n",
    "                action_tokens.ys[i],\n",
    "            )\n",
    "            ms = Timestep(\n",
    "                text_tokens.ms[i],\n",
    "                image_tokens.ms[i],\n",
    "                discrete_tokens.ms[i],\n",
    "                SEPARATOR_TOKEN,\n",
    "                action_tokens.ms[i],\n",
    "            )\n",
    "            timesteps.append([xs, ys, ms])\n",
    "        sequenced.append(timesteps)\n",
    "    return sequenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f4b6344a-4297-4e6f-9d3c-126a1a5a1aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokensObservation(xs=tensor([50257, 50258, 50259, 50259, 50259, 50259, 50259, 50259, 50260, 50260,\n",
       "        50260, 50260, 50260, 50260, 50260, 50260, 50260, 50260, 50260, 50260],\n",
       "       dtype=torch.int32), ys=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=torch.int32), ms=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=torch.int32))"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_tokens = tokenize_observation(\n",
    "    VOCAB_SIZE,\n",
    "    minigrid_dataset[0].observations[\"direction\"]\n",
    ")\n",
    "discrete_tokens\n",
    "# minigrid_dataset[0].observations[\"direction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61abcc9-36d0-41ce-844b-b1e075f4e32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "51445cf6-cfeb-4225-8c78-19339f963e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = minigrid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "38c007d7-cbad-4fc2-9a6d-6e714925954b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 7, 3)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = sample.observations[\"image\"][0:4]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f9bdc357-dec8-4645-a17c-255f90f1ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = torch.stack([minigrid_image_resize(minigrid_to_rgb(i)) for i in image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0b1efc95-57dd-4d20-9abe-64828dd816ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36, 48])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_patches(images_resized, CONTROL_PATCH_SIZE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b1c4e689-8f34-4058-9dd9-ba9c5a68cd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 24, 24])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "25eff6df-333e-4f65-abaf-ead8224de778",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_image(images_resized, patch_size=CONTROL_PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "70926f9f-e844-48e5-bfc3-dbc3d600c199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 36, 48]), torch.Size([4, 36]))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.xs.shape, tokens.ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "58aed3a4-2420-4a6a-8e51-bdeba610592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((tokens.xs.size(2) / 3) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "aac27be3-d2ea-4766-be1d-4c99d07bdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tokens.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352f50b-b5a3-4b91-a808-eae444cd4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patch_rows, n_patch_cols = n_patch_rows_cols(self.patch_size, self.patch_size, heights, widths)\n",
    "images_embeddings = []\n",
    "embeddings = self.resnet(tokens)\n",
    "for i, token in enumerate(tokens):\n",
    "    row_interval, col_interval = intervals(n_patch_rows[i].item(), n_patch_cols[i].item())\n",
    "    image_embeddings = []\n",
    "    for j in range(image.size(0)):\n",
    "        row_idx, col_idx = patch_position_sample(row_interval, col_interval, j, mode=\"training\")\n",
    "        embeddings[i][j] += _patch_position_row_embedding(row_idx) + _patch_position_col_embedding(col_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88cd0c-dd01-45ad-8126-16b5158185de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "99826b1a-f9f7-497f-8c87-942c0b3d04d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 36, 48])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, 36, 48]\n",
    "# 1 batch\n",
    "#     36 patches\n",
    "#         4x4x3 HxWxC\n",
    "image_tokens.xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8770886b-e76a-4f03-a764-bf73bc3b6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_dataloader = DataLoader(\n",
    "    minigrid_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=partial(\n",
    "        minigrid_collate_fn, \n",
    "        partial(tokenize_text, _text_tokenizer), \n",
    "        partial(tokenize_image),\n",
    "        partial(tokenize_observation, _text_tokenizer.vocab_size),\n",
    "        _text_tokenizer.vocab_size,\n",
    "    ),\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "28fa3ffe-0cfd-4d07-a801-e31385074196",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ctrl_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3bc784ec-c501-493e-b96d-263ea4424a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa83ab-f1b8-4c6d-aca4-7b33025ff613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "16e51fcb-e624-4e43-9950-c201747f7890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch[0] is the first sample of the batch; an episode\n",
    "len(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "14aac02e-ff78-4bb3-a653-658fe0334dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[0][0] is the first timestep of the first episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1541c9ea-f1f9-47c7-a80f-d9a08310112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1]).size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "22a22f04-1333-4b07-9277-6c7ad0d5ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1024, 36, 1, 1, 1]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.size(0) for t in batch[0][0][0]._asdict().values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "787b4baf-51a5-49ed-8fa8-9056e1e3948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestep(text=tensor([  262,  3061, 50256,  ..., 50256, 50256, 50256]), image=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), discrete=tensor([0], dtype=torch.int32), separator=tensor([91]), action=tensor([0], dtype=torch.int32))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "283249ff-1176-4c0a-8945-3fda113db68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestep(text=tensor([16250,   262,  3061,  ..., 50256, 50256, 50256]), image=tensor([[-0.0011, -0.0011, -0.0011,  ..., -0.2887, -0.2887, -0.2887],\n",
       "        [-0.0011, -0.0011, -0.0011,  ..., -0.2887, -0.2887, -0.2887],\n",
       "        [-0.0011, -0.0962, -0.1981,  ..., -0.2276, -0.1619, -0.0962],\n",
       "        ...,\n",
       "        [-0.2670, -0.2670, -0.2670,  ..., -0.0629, -0.0629, -0.0629],\n",
       "        [-0.2670, -0.2670, -0.2670,  ..., -0.0629, -0.0629, -0.0629],\n",
       "        [-0.2670, -0.2670, -0.2670,  ..., -0.0629, -0.0629, -0.0629]]), discrete=tensor([50257], dtype=torch.int32), separator=tensor([91]), action=tensor([50258], dtype=torch.int32))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch[0][0][0] is the xs of the first timestep\n",
    "# batch[0][0][1] is the ys\n",
    "#            [2] is the ms\n",
    "batch[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e7190849-289e-4b66-a7fa-8e14c5146536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 48])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0][0].image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68547f8-f97d-4547-86d2-68ac7e553987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1cf6c052-2f09-4832-add9-95ed8f0802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "00d46b85-985d-42c3-8221-7f17b21816f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "36ced850-2cd1-4270-9246-fac0a3deef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From section 2.2 of the Gato paper:\n",
    "#\n",
    "#    Tokens belonging to image patches for any time-step are embedded using a\n",
    "#    single ResNet (He et al., 2016a) block to obtain a vector per patch. For\n",
    "#    image patch token embeddings, we also add a learnable within-image position\n",
    "#    encoding vector.\n",
    "class ResNetV2Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, num_groups=24):\n",
    "        super(ResNetV2Block, self).__init__()\n",
    "        self.gn1 = nn.GroupNorm(1, in_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.gn2 = nn.GroupNorm(num_groups, out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, CHW = x.shape\n",
    "        # TODO: Remove these hardcoded values.\n",
    "        out = rearrange(x, 'b t (c h w) -> (b t) c h w', c=3, h=16)\n",
    "        out = self.gn1(out)\n",
    "        out = self.gelu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.gn2(out)\n",
    "        out = self.gelu(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + rearrange(out, '(b t) c h w -> b t (c h w)', b=B, t=T)\n",
    "\n",
    "_image_embedding = ResNetV2Block(3, EMBEDDING_DIM)\n",
    "# This _position_embedding doesn't match exactly what's in the Gato paper.\n",
    "# The gato/policy/embeddings.py file has the exact implementation from the paper.\n",
    "# https://github.com/eihli/NEKO/blob/explore-simplify-dataset-dataloader/gato/policy/embeddings.py#L91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a9c65e0d-8b1a-425a-876a-7da25f49460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_patches(patch_size, image_dim):\n",
    "    return (image_dim / patch_size).to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45a3806d-4d33-4910-b224-234b280f54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGato(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_length,\n",
    "        embedding_dims,\n",
    "        vocab_size,\n",
    "        text_tokenizer=None,\n",
    "        patch_size=12,\n",
    "    ):\n",
    "        assert text_tokenizer, \"text_tokenizer is a required arg\"\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embedding_dim = embedding_dims\n",
    "        self.patch_size = patch_size\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        \n",
    "        self.text_embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embedding_dim,\n",
    "        )\n",
    "        self.resnet = ResNetV2Block(3, self.embedding_dims)\n",
    "        self.row_embedding = nn.Embedding(128, self.embedding_dim)\n",
    "        self.col_embedding = nn.Embedding(128, self.embedding_dim)\n",
    "        self.timestep_position_embedding = nn.Embedding(512, self.embedding_dim)\n",
    "        self.discrete_embedding = nn.Embedding(\n",
    "            1024,  # Number of discrete bins.\n",
    "            self.embedding_dim,\n",
    "        )\n",
    "        \n",
    "        self.configuration = GPT2Config(\n",
    "            n_layer=2,\n",
    "            n_head=2,\n",
    "            n_embd=self.embedding_dim\n",
    "        )\n",
    "        self.transformer = GPT2Model(configuration)        \n",
    "\n",
    "        self.lm_head = nn.Linear(model.config.hidden_size, _text_tokenizer.vocab_size).to(device)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.text_tokenizer.vocab_size\n",
    "\n",
    "    def embed_text(self, tokens):\n",
    "        return self.text_embedding(tokens)[\"input_ids\"]\n",
    "\n",
    "    def embed_image(self, tokens):\n",
    "        if not tokens:\n",
    "            return torch.tensor()\n",
    "        # [        heights,         widths]\n",
    "        # [[640, 640, 640], [480, 480, 480]]\n",
    "        heights, widths = torch.tensor([[tokens.size(1)], [tokens.size(2)]]).repeat(1, tokens.size(0))\n",
    "        \n",
    "        n_patch_rows, n_patch_cols = n_patch_rows_cols(self.patch_size, self.patch_size, heights, widths)\n",
    "        images_embeddings = []\n",
    "        embeddings = self.resnet(tokens)\n",
    "        for i, token in enumerate(tokens):\n",
    "            row_interval, col_interval = intervals(n_patch_rows[i].item(), n_patch_cols[i].item())\n",
    "            image_embeddings = []\n",
    "            for j in range(image.size(0)):\n",
    "                row_idx, col_idx = patch_position_sample(row_interval, col_interval, j, mode=\"training\")\n",
    "                embeddings[i][j] += _patch_position_row_embedding(row_idx) + _patch_position_col_embedding(col_idx)        \n",
    "        return embed_image(n_patch_rows, n_patch_cols, tokens)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6351f-388f-4d97-9596-7ee6999547e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_image(n_patch_rows, n_patch_cols, images):\n",
    "    images_embeddings = []\n",
    "    embeddings = self.resnet(images)\n",
    "    for i, image in enumerate(images):\n",
    "        row_interval, col_interval = intervals(n_patch_rows[i].item(), n_patch_cols[i].item())\n",
    "        image_embeddings = []\n",
    "        for j in range(image.size(0)):\n",
    "            row_idx, col_idx = patch_position_sample(row_interval, col_interval, j, mode=\"training\")\n",
    "            embeddings[i][j] += _patch_position_row_embedding(row_idx) + _patch_position_col_embedding(col_idx)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab476e07-dc4f-44d9-a9c1-1e70154a7634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[640, 640, 640, 640, 640],\n",
       "        [480, 480, 480, 480, 480]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.ones((4, 640, 480))\n",
    "torch.tensor([[i] for i in image.shape[1:3]]).repeat(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b3006-c8c2-4e61-a9ca-a7f75138d456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb865bd6-97c1-409a-b00c-8c404d0fb199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52334dbb-364d-4be8-a465-de89040dcadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dce1c-0538-4489-a501-41e71307b5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf32c1f-b56c-4731-a7a2-d13a5e78c443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57bd2b-1079-4837-9ebe-2007d2cc2dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad495396-0e5d-4d06-9909-978a6341471b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df419a35-346f-4ea6-b225-30c36b9bb845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c98be-76b1-449b-b549-3d4663da0d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
